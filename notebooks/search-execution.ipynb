{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic Review - Literature Search Execution\n",
    "\n",
    "This notebook executes literature searches based on a search strategy JSON file and generates a search execution JSON for nanopublication.\n",
    "\n",
    "**All configuration is read from JSON:**\n",
    "- Databases\n",
    "- Time period\n",
    "- Search terms with labels\n",
    "- Search groups (Boolean structure)\n",
    "\n",
    "**Outputs:**\n",
    "- Search results (CSV, RIS, BibTeX, JSON)\n",
    "- Search execution JSON (for nanopublication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (uncomment if needed)\n",
    "# !pip install requests arxiv biopython pandas -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optional Dependencies:\n",
      "  arxiv: ✓ installed\n",
      "  biopython: ✓ installed\n",
      "\n",
      "Database Support:\n",
      "  OpenAlex: ✓ API (no key required)\n",
      "  Semantic Scholar: ✓ API (no key required)\n",
      "  Europe PMC: ✓ API (no key required)\n",
      "  arXiv: ✓ API\n",
      "  PubMed: ✓ API\n",
      "  CORE: ✓ API (requires free key from core.ac.uk)\n",
      "  Google Scholar: ⚠ Manual only (use Publish or Perish)\n",
      "  BASE: ⚠ Manual only\n",
      "  Web of Science: ⚠ Requires institutional access\n",
      "  Scopus: ⚠ Requires institutional access\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "sys.path.insert(0, str(Path('.').resolve()))\n",
    "\n",
    "from search_utils import (\n",
    "    SearchExecutor,\n",
    "    deduplicate_by_doi,\n",
    "    print_dependency_status,\n",
    "    load_config_from_json,\n",
    "    build_boolean_query\n",
    ")\n",
    "\n",
    "print_dependency_status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration from JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============== SET YOUR CONFIG ==============\n",
    "\n",
    "JSON_CONFIG_PATH = \"../inputs/pets-biodiversity/search-strategy-privacy-pet-biodiversity.json\"\n",
    "EMAIL = \"anne.fouilloux@gmail.com\"\n",
    "MAX_RESULTS = 500\n",
    "OUTPUT_DIR = Path(\"./pets-biodiversity/results\")\n",
    "\n",
    "# ============================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Strategy: Privacy-Enhancing Technologies for Geospatial Biodiversity Data Sharing - Literature Search\n",
      "Time period: 2010 - 2026\n",
      "\n",
      "Databases (3):\n",
      "  - https://arxiv.org/\n",
      "  - https://www.semanticscholar.org/\n",
      "  - https://openalex.org/\n",
      "\n",
      "Methodology: Search strategy for scoping review on privacy-enhancing technologies applicable to geospatial biodiversity data. All terms backed by Wikidata URIs. Removed broad terms (blockchain, federated learning,...\n"
     ]
    }
   ],
   "source": [
    "# Load configuration\n",
    "config = load_config_from_json(JSON_CONFIG_PATH)\n",
    "\n",
    "print(f\"Search Strategy: {config['label']}\")\n",
    "print(f\"Time period: {config['start_year']} - {config['end_year']}\")\n",
    "print(f\"\\nDatabases ({len(config['databases'])}):\")\n",
    "for db in config['databases']:\n",
    "    print(f\"  - {db}\")\n",
    "print(f\"\\nMethodology: {config['methodology_notes'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Search Groups (from JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean query structure:\n",
      "============================================================\n",
      "\n",
      "PRIVACY_METHODS:\n",
      "  - geo-privacy\n",
      "  - geoprivacy\n",
      "  - differential privacy\n",
      "  - k-anonymity\n",
      "  - secure multi-party computation\n",
      "  - data anonymization\n",
      "  - homomorphic encryption\n",
      "\n",
      "BIODIVERSITY:\n",
      "  - biodiversity\n",
      "  - species occurrence\n",
      "  - GBIF\n",
      "  - species distribution model\n",
      "\n",
      "============================================================\n",
      "Query: (geo-privacy OR geoprivacy OR differential privacy OR k-anonymity OR secure multi-party computation OR data anonymization OR homomorphic encryption) AND (biodiversity OR species occurrence OR GBIF OR species distribution model)\n"
     ]
    }
   ],
   "source": [
    "# Search groups defined in JSON\n",
    "SEARCH_TERMS = config['search_groups']\n",
    "\n",
    "# Build the Boolean query string\n",
    "BOOLEAN_QUERY = build_boolean_query(SEARCH_TERMS)\n",
    "\n",
    "print(\"Boolean query structure:\")\n",
    "print(\"=\"*60)\n",
    "for group, terms in SEARCH_TERMS.items():\n",
    "    print(f\"\\n{group.upper()}:\")\n",
    "    for term in terms:\n",
    "        print(f\"  - {term}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Query: {BOOLEAN_QUERY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Execute Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search started: 2026-01-10T15:55:26.325542\n",
      "\n",
      "Searching arXiv: (all:\"geo-privacy\" OR all:\"geoprivacy\" OR all:\"differential privacy\" OR all:\"k-anonymity\" OR all:...\n",
      "arXiv: Retrieved 0 records\n",
      "Searching Semantic Scholar: (geo-privacy OR geoprivacy OR differential privacy OR k-anonymity OR secure multi-party computati...\n",
      "  (S2 query: +geo-privacy +biodiversity geoprivacy differential privacy s...)\n",
      "Semantic Scholar: Total results available: 0\n",
      "Semantic Scholar: Retrieved 0 records\n",
      "Searching OpenAlex: (geo-privacy OR geoprivacy OR differential privacy OR k-anonymity OR secure multi-party computati...\n",
      "  (OpenAlex filter: publication_year:2010-2026,title_and_abstract.search:geo-privacy|geoprivacy|\"differential privacy\"|k...)\n",
      "OpenAlex: Total results available: 21\n",
      "OpenAlex: Retrieved 21 records\n"
     ]
    }
   ],
   "source": [
    "# Create search executor\n",
    "executor = SearchExecutor(\n",
    "    search_terms=SEARCH_TERMS,\n",
    "    start_year=config['start_year'],\n",
    "    end_year=config['end_year'],\n",
    "    email=EMAIL,\n",
    "    max_results=MAX_RESULTS,\n",
    "    databases=config['databases']\n",
    ")\n",
    "\n",
    "SEARCH_DATE = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(f\"Search started: {datetime.now().isoformat()}\\n\")\n",
    "\n",
    "# Run searches\n",
    "all_records = executor.run_all_searches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SEARCH RESULTS SUMMARY\n",
      "============================================================\n",
      "Search Date: 2026-01-10T15:55:26.325384\n",
      "Date Range: 2010-2026\n",
      "\n",
      "arxiv:\n",
      "  - Total available: 0\n",
      "  - Retrieved: 0\n",
      "semanticscholar:\n",
      "  - Total available: 0\n",
      "  - Retrieved: 0\n",
      "openalex:\n",
      "  - Total available: 21\n",
      "  - Retrieved: 21\n",
      "\n",
      "TOTAL RECORDS (before deduplication): 21\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "executor.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Deduplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEDUPLICATION (DOI-based):\n",
      "  Total records: 21\n",
      "  Duplicates removed: 0\n",
      "  Records without DOI: 1\n",
      "  Unique records: 21\n"
     ]
    }
   ],
   "source": [
    "unique_records, dup_count, no_doi_count = deduplicate_by_doi(all_records)\n",
    "\n",
    "print(f\"DEDUPLICATION (DOI-based):\")\n",
    "print(f\"  Total records: {len(all_records)}\")\n",
    "print(f\"  Duplicates removed: {dup_count}\")\n",
    "print(f\"  Records without DOI: {no_doi_count}\")\n",
    "print(f\"  Unique records: {len(unique_records)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported 21 records to pets-biodiversity/results/search_results_combined.csv\n",
      "Exported 21 records to pets-biodiversity/results/search_results_combined.ris\n",
      "Exported 21 records to pets-biodiversity/results/search_results_combined.bib\n",
      "Exported 21 records to pets-biodiversity/results/search_results_combined.json\n",
      "Saved search summary to pets-biodiversity/results/search_summary.json\n",
      "\n",
      "Files saved to: /Users/annef/Documents/FAIR2Adapt/systematic-review-pipeline/notebooks/pets-biodiversity/results\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "executor.export_results(\n",
    "    unique_records,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    formats=[\"csv\", \"ris\", \"bibtex\", \"json\"]\n",
    ")\n",
    "\n",
    "print(f\"\\nFiles saved to: {OUTPUT_DIR.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique records: 21\n",
      "\n",
      "By source:\n",
      "source\n",
      "OpenAlex    21\n",
      "\n",
      "By year:\n",
      "year\n",
      "2013    1\n",
      "2020    3\n",
      "2021    1\n",
      "2022    7\n",
      "2024    2\n",
      "2025    7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(unique_records)\n",
    "\n",
    "print(f\"Total unique records: {len(df)}\")\n",
    "print(f\"\\nBy source:\")\n",
    "print(df[\"source\"].value_counts().to_string())\n",
    "print(f\"\\nBy year:\")\n",
    "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "print(df[\"year\"].value_counts().sort_index().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample titles (first 10):\n",
      "1. An Efficient Approach Based on Privacy-Preserving Deep Learning for Satellite Image Classi...\n",
      "2. LUCAS cover photos 2006–2018 over the EU: 874 646 spatially distributed geo-tagged close-u...\n",
      "3. Ethics of Environmental and Biodiversity Data. When Data Travel, Do the Benefits Return? P...\n",
      "4. Ethics of Environmental and Biodiversity Data. When Data Travel, Do the Benefits Return? P...\n",
      "5. Ethics of Environmental and Biodiversity Data. When Data Travel, Do the Benefits Return? P...\n",
      "6. Exploring the Methods and the Need for Data Anonymization of Species Locational Data\n",
      "7. Fisheries Inspection in Portuguese Waters from 2015 to 2023\n",
      "8. LUCAS Cover photos 2006–2018 over the EU: 874,646 spatially distributed geo-tagged close-u...\n",
      "9. The Importance of Multilevel and Multidimensional Approaches to Integrated Resources Manag...\n",
      "10. Flora of Russia on iNaturalist backup 2020 Sep 08 (750K + 136K records)\n"
     ]
    }
   ],
   "source": [
    "# Sample titles\n",
    "print(\"\\nSample titles (first 10):\")\n",
    "for i, title in enumerate(df[\"title\"].head(10), 1):\n",
    "    print(f\"{i}. {str(title)[:90]}...\" if len(str(title)) > 90 else f\"{i}. {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. PRISMA Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRISMA FLOW - IDENTIFICATION\n",
      "========================================\n",
      "arxiv: 0\n",
      "semanticscholar: 0\n",
      "openalex: 21\n",
      "\n",
      "Total identified: 21\n",
      "After deduplication: 21\n"
     ]
    }
   ],
   "source": [
    "print(\"PRISMA FLOW - IDENTIFICATION\")\n",
    "print(\"=\"*40)\n",
    "for db, counts in executor.results_summary[\"databases\"].items():\n",
    "    if counts.get('total_available') != 'manual':\n",
    "        print(f\"{db}: {counts['total_available']}\")\n",
    "    else:\n",
    "        print(f\"{db}: (manual search required)\")\n",
    "print(f\"\\nTotal identified: {len(all_records)}\")\n",
    "print(f\"After deduplication: {len(unique_records)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Search Execution JSON\n",
    "\n",
    "This JSON file documents the search execution and will be used to create a nanopublication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured 3 database searches:\n",
      "  arXiv: 0\n",
      "  Semantic Scholar: 0\n",
      "  OpenAlex: 21\n"
     ]
    }
   ],
   "source": [
    "# Database metadata mapping\n",
    "DB_METADATA = {\n",
    "    \"arxiv\": {\n",
    "        \"url\": \"https://arxiv.org/\",\n",
    "        \"label\": \"arXiv\",\n",
    "        \"export_format\": \"BibTeX\",\n",
    "        \"notes\": \"Preprints in cs.CV, cs.LG, eess.IV categories\"\n",
    "    },\n",
    "    \"openalex\": {\n",
    "        \"url\": \"https://openalex.org/\",\n",
    "        \"label\": \"OpenAlex\",\n",
    "        \"export_format\": \"BibTeX\",\n",
    "        \"notes\": \"Comprehensive bibliographic coverage, free API\"\n",
    "    },\n",
    "    \"semanticscholar\": {\n",
    "        \"url\": \"https://www.semanticscholar.org/\",\n",
    "        \"label\": \"Semantic Scholar\",\n",
    "        \"export_format\": \"BibTeX\",\n",
    "        \"notes\": \"AI-enhanced discovery, free API\"\n",
    "    },\n",
    "    \"pubmed\": {\n",
    "        \"url\": \"https://pubmed.ncbi.nlm.nih.gov/\",\n",
    "        \"label\": \"PubMed\",\n",
    "        \"export_format\": \"RIS/NBIB\",\n",
    "        \"notes\": \"Biomedical focus\"\n",
    "    },\n",
    "    \"europepmc\": {\n",
    "        \"url\": \"https://europepmc.org/\",\n",
    "        \"label\": \"Europe PMC\",\n",
    "        \"export_format\": \"RIS\",\n",
    "        \"notes\": \"European repository content\"\n",
    "    },\n",
    "    \"core.ac.uk\": {\n",
    "        \"url\": \"https://core.ac.uk/\",\n",
    "        \"label\": \"CORE\",\n",
    "        \"export_format\": \"BibTeX\",\n",
    "        \"notes\": \"Open access aggregator\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Build db_searches array\n",
    "db_searches = []\n",
    "for db_key, counts in executor.results_summary[\"databases\"].items():\n",
    "    metadata = DB_METADATA.get(db_key, {\n",
    "        \"url\": f\"https://{db_key}/\",\n",
    "        \"label\": db_key,\n",
    "        \"export_format\": \"RIS\",\n",
    "        \"notes\": \"\"\n",
    "    })\n",
    "    \n",
    "    db_search = {\n",
    "        \"database_url\": metadata[\"url\"],\n",
    "        \"database_label\": metadata[\"label\"],\n",
    "        \"search_query\": BOOLEAN_QUERY,\n",
    "        \"filters\": f\"{config['start_year']}-{config['end_year']}\",\n",
    "        \"results_count\": counts.get('total_available', 0) if counts.get('total_available') != 'manual' else 0,\n",
    "        \"export_format\": metadata[\"export_format\"],\n",
    "        \"notes\": metadata[\"notes\"]\n",
    "    }\n",
    "    db_searches.append(db_search)\n",
    "\n",
    "print(f\"Captured {len(db_searches)} database searches:\")\n",
    "for db in db_searches:\n",
    "    print(f\"  {db['database_label']}: {db['results_count']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search execution JSON generated\n"
     ]
    }
   ],
   "source": [
    "# Load author info from original config\n",
    "with open(JSON_CONFIG_PATH, \"r\") as f:\n",
    "    original_config = json.load(f)\n",
    "\n",
    "author_info = original_config.get(\"author\", {\n",
    "    \"orcid\": \"0000-0000-0000-0000\",\n",
    "    \"name\": \"Unknown\"\n",
    "})\n",
    "\n",
    "# Generate search execution JSON (matching quantum-biodiversity format)\n",
    "search_execution = {\n",
    "    \"_instructions\": \"Update screening fields after completing title/abstract and full-text screening.\",\n",
    "    \"author\": author_info,\n",
    "    \"search_execution_dataset\": {\n",
    "        \"label\": config['label'].replace(\"Literature Search\", \"Search Execution Results\"),\n",
    "        \"part_of\": original_config.get(\"search_strategy\", {}).get(\"part_of\", \"\"),\n",
    "        \"creation_date\": SEARCH_DATE,\n",
    "        \"db_searches\": db_searches,\n",
    "        \"deduplication_methodology\": f\"Records from {len(db_searches)} databases combined. Automatic deduplication on DOI field. {dup_count} duplicates removed. {no_doi_count} records without DOI kept for title-based deduplication in screening tool.\",\n",
    "        \"review_methodology\": \"UPDATE: Describe your review methodology (e.g., single/dual reviewer, validation sample).\",\n",
    "        \"screening_methodology\": \"UPDATE: Describe screening approach (e.g., Rayyan, ASReview, manual).\",\n",
    "        \"screened_record_count\": str(len(unique_records)),\n",
    "        \"fulltext_screened_record_count\": \"UPDATE: Number after title/abstract screening\",\n",
    "        \"final_included_study_count\": \"UPDATE: Final included studies\",\n",
    "        \"exclusion_breakdown\": \"UPDATE: Provide breakdown of exclusions at each stage (e.g., Title/abstract screening: X excluded as not relevant. Full-text screening: Y excluded for reason Z.)\",\n",
    "        \"dataset_file_location\": \"UPDATE: Add Zenodo DOI or repository URL\",\n",
    "        \"limitations\": \"UPDATE: Document limitations (e.g., database coverage, language restrictions, grey literature exclusion).\"\n",
    "    },\n",
    "    \"output\": {\n",
    "        \"filename\": original_config.get(\"output\", {}).get(\"filename\", \"search-execution\").replace(\"search-strategy\", \"search-execution\")\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Search execution JSON generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: pets-biodiversity/results/privacy-pet-biodiversity-search-execution.json\n",
      "\n",
      "============================================================\n",
      "⚠ FIELDS TO UPDATE AFTER SCREENING:\n",
      "============================================================\n",
      "  - review_methodology\n",
      "  - screening_methodology\n",
      "  - fulltext_screened_record_count\n",
      "  - final_included_study_count\n",
      "  - exclusion_breakdown\n",
      "  - dataset_file_location\n",
      "  - limitations\n"
     ]
    }
   ],
   "source": [
    "# Save search execution JSON\n",
    "execution_filename = search_execution[\"output\"][\"filename\"] + \".json\"\n",
    "execution_path = OUTPUT_DIR / execution_filename\n",
    "\n",
    "with open(execution_path, \"w\") as f:\n",
    "    json.dump(search_execution, f, indent=2)\n",
    "\n",
    "print(f\"Saved: {execution_path}\")\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"⚠ FIELDS TO UPDATE AFTER SCREENING:\")\n",
    "print(\"=\"*60)\n",
    "print(\"  - review_methodology\")\n",
    "print(\"  - screening_methodology\")\n",
    "print(\"  - fulltext_screened_record_count\")\n",
    "print(\"  - final_included_study_count\")\n",
    "print(\"  - exclusion_breakdown\")\n",
    "print(\"  - dataset_file_location\")\n",
    "print(\"  - limitations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated search execution JSON:\n",
      "============================================================\n",
      "{\n",
      "  \"_instructions\": \"Update screening fields after completing title/abstract and full-text screening.\",\n",
      "  \"author\": {\n",
      "    \"orcid\": \"0000-0002-1784-2920\",\n",
      "    \"name\": \"Anne Fouilloux\"\n",
      "  },\n",
      "  \"search_execution_dataset\": {\n",
      "    \"label\": \"Privacy-Enhancing Technologies for Geospatial Biodiversity Data Sharing - Search Execution Results\",\n",
      "    \"part_of\": \"https://w3id.org/np/RAqmVeNbWgL7sNtsr9GqdX0ZTa6aQf3itQmort-JMy4tM\",\n",
      "    \"creation_date\": \"2026-01-10\",\n",
      "    \"db_searches\": [\n",
      "      {\n",
      "        \"database_url\": \"https://arxiv.org/\",\n",
      "        \"database_label\": \"arXiv\",\n",
      "        \"search_query\": \"(geo-privacy OR geoprivacy OR differential privacy OR k-anonymity OR secure multi-party computation OR data anonymization OR homomorphic encryption) AND (biodiversity OR species occurrence OR GBIF OR species distribution model)\",\n",
      "        \"filters\": \"2010-2026\",\n",
      "        \"results_count\": 0,\n",
      "        \"export_format\": \"BibTeX\",\n",
      "        \"notes\": \"Preprints in cs.CV, cs.LG, eess.IV categories\"\n",
      "      },\n",
      "      {\n",
      "        \"database_url\": \"https://www.semanticscholar.org/\",\n",
      "        \"database_label\": \"Semantic Scholar\",\n",
      "        \"search_query\": \"(geo-privacy OR geoprivacy OR differential privacy OR k-anonymity OR secure multi-party computation OR data anonymization OR homomorphic encryption) AND (biodiversity OR species occurrence OR GBIF OR species distribution model)\",\n",
      "        \"filters\": \"2010-2026\",\n",
      "        \"results_count\": 0,\n",
      "        \"export_format\": \"BibTeX\",\n",
      "        \"notes\": \"AI-enhanced discovery, free API\"\n",
      "      },\n",
      "      {\n",
      "        \"database_url\": \"https://openalex.org/\",\n",
      "        \"database_label\": \"OpenAlex\",\n",
      "        \"search_query\": \"(geo-privacy OR geoprivacy OR differential privacy OR k-anonymity OR secure multi-party computation OR data anonymization OR homomorphic encryption) AND (biodiversity OR species occurrence OR GBIF OR species distribution model)\",\n",
      "        \"filters\": \"2010-2026\",\n",
      "        \"results_count\": 21,\n",
      "        \"export_format\": \"BibTeX\",\n",
      "        \"notes\": \"Comprehensive bibliographic coverage, free API\"\n",
      "      }\n",
      "    ],\n",
      "    \"deduplication_methodology\": \"Records from 3 databases combined. Automatic deduplication on DOI field. 0 duplicates removed. 1 records without DOI kept for title-based deduplication in screening tool.\",\n",
      "    \"review_methodology\": \"UPDATE: Describe your review methodology (e.g., single/dual reviewer, validation sample).\",\n",
      "    \"screening_methodology\": \"UPDATE: Describe screening approach (e.g., Rayyan, ASReview, manual).\",\n",
      "    \"screened_record_count\": \"21\",\n",
      "    \"fulltext_screened_record_count\": \"UPDATE: Number after title/abstract screening\",\n",
      "    \"final_included_study_count\": \"UPDATE: Final included studies\",\n",
      "    \"exclusion_breakdown\": \"UPDATE: Provide breakdown of exclusions at each stage (e.g., Title/abstract screening: X excluded as not relevant. Full-text screening: Y excluded for reason Z.)\",\n",
      "    \"dataset_file_location\": \"UPDATE: Add Zenodo DOI or repository URL\",\n",
      "    \"limitations\": \"UPDATE: Document limitations (e.g., database coverage, language restrictions, grey literature exclusion).\"\n",
      "  },\n",
      "  \"output\": {\n",
      "    \"filename\": \"privacy-pet-biodiversity-search-execution\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Preview the generated JSON\n",
    "print(\"\\nGenerated search execution JSON:\")\n",
    "print(\"=\"*60)\n",
    "print(json.dumps(search_execution, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. **Import to Rayyan/ASReview**: Upload `search_results_combined.ris`\n",
    "2. **Title/abstract screening**: Apply inclusion criteria\n",
    "3. **Full-text screening**: Review candidates\n",
    "4. **Update search execution JSON**: Fill in screening results\n",
    "5. **Create nanopublication**: Run search-execution-nanopub-from-json.ipynb\n",
    "6. **Data extraction**: Create nanopublications for included papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
