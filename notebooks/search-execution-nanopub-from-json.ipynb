{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRISMA Search Execution Dataset Nanopublication\n",
    "\n",
    "**Notebook 2 of 2** - Creates the aggregating Search Execution Dataset that references individual database searches.\n",
    "\n",
    "## Template\n",
    "- `RAV_H3udaSzxYOhhR0t-q7PKS6URwauD_Z5sMLbHmM2x0` - Declaring a search execution dataset\n",
    "\n",
    "## Features\n",
    "- **Create new** or **supersede existing** nanopub\n",
    "- References external database search nanopubs (from Notebook 1)\n",
    "- Includes `nt:hasLabelFromApi` for proper Nanodash display\n",
    "\n",
    "## Prerequisites\n",
    "- **Notebook 1 completed**: Database search nanopubs published\n",
    "- URIs file from Notebook 1: `*-db-search-uris.json`\n",
    "- Your original configuration file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Load Configuration and Database Search URIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config: Quantum Computing for Biodiversity - Search Execution Results\n",
      "Author: Anne Fouilloux\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to your original configuration file\n",
    "CONFIG_FILE = \"../inputs/quantum-biodiversity/search-execution-quantum-biodiversity.json\"\n",
    "\n",
    "# Path to URIs file from Notebook 1\n",
    "URIS_FILE = \"../inputs/quantum-biodiversity/quantum-biodiversity-search-execution-db-search-uris.json\"\n",
    "\n",
    "# Load config\n",
    "with open(CONFIG_FILE, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "sed = config['search_execution_dataset']\n",
    "print(f\"Config: {sed['label']}\")\n",
    "print(f\"Author: {config['author']['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 6 database search URIs:\n",
      "  • OpenAlex: https://w3id.org/np/RAkV7KfvYqIpFLfMqqLmZxyCpr4VFcgE4ln3FRYrZwdaE/search\n",
      "  • arXiv: https://w3id.org/np/RApg5W58ZcDLDtKF2txz-SrOVsjM-3lpoPkrWGOFcigZU/search\n",
      "  • Semantic Scholar: https://w3id.org/np/RARwCFSuFUqEE0OPW8CeynB8cx4zemGB09obBA9eXfo78/search\n",
      "  • PubMed: https://w3id.org/np/RAkZsd1zUQn8lXlN8yNQgZBO2W4iuZhMQDE0r-kBXrF6g/search\n",
      "  • IEEE Xplore (OA only): https://w3id.org/np/RAVBmg81fxSEFhZ5W9D89XxBR2Scts7yWSWFtFY4OX5UI/search\n",
      "  • Europe PMC: https://w3id.org/np/RASfip5KQntGv4ACoKui2ZBwhSQKTQPPClPC1zyQHo29M/search\n"
     ]
    }
   ],
   "source": [
    "# Load database search URIs from Notebook 1\n",
    "try:\n",
    "    with open(URIS_FILE, 'r') as f:\n",
    "        uris_data = json.load(f)\n",
    "    \n",
    "    db_searches = uris_data['database_searches']\n",
    "    print(f\"Loaded {len(db_searches)} database search URIs:\")\n",
    "    for item in db_searches:\n",
    "        print(f\"  • {item['database']}: {item['search_uri']}\")\n",
    "    \n",
    "    DB_SEARCH_URIS = [item['search_uri'] for item in db_searches]\n",
    "    LABELS_MAP = {item['search_uri']: item['label'] for item in db_searches}\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ URIs file not found: {URIS_FILE}\")\n",
    "    print(\"\\nEither:\")\n",
    "    print(\"  1. Run Notebook 1 first to publish database searches, or\")\n",
    "    print(\"  2. Manually enter URIs in the cell below\")\n",
    "    \n",
    "    DB_SEARCH_URIS = []\n",
    "    LABELS_MAP = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1b: Configure Supersedes (Optional)\n",
    "\n",
    "If you want to **update an existing nanopub**, set the URI here. The new nanopub will supersede the old one.\n",
    "\n",
    "The old nanopub will be marked as outdated in Nanodash and queries will return the new version instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Will SUPERSEDE existing nanopub:\n",
      "   https://w3id.org/np/RAMPy96eCLCXlGR9VvCVf6rJmpN_DlxxarMGm91_5n-O8\n",
      "\n",
      "   The old nanopub will be marked as outdated.\n",
      "   View old: https://nanodash.knowledgepixels.com/explore?id=https://w3id.org/np/RAMPy96eCLCXlGR9VvCVf6rJmpN_DlxxarMGm91_5n-O8\n"
     ]
    }
   ],
   "source": [
    "# Set this to supersede an existing nanopub (set to None to create new)\n",
    "SUPERSEDES_URI = \"https://w3id.org/np/RAMPy96eCLCXlGR9VvCVf6rJmpN_DlxxarMGm91_5n-O8\"\n",
    "\n",
    "if SUPERSEDES_URI:\n",
    "    print(f\"⚠️  Will SUPERSEDE existing nanopub:\")\n",
    "    print(f\"   {SUPERSEDES_URI}\")\n",
    "    print(f\"\\n   The old nanopub will be marked as outdated.\")\n",
    "    print(f\"   View old: https://nanodash.knowledgepixels.com/explore?id={SUPERSEDES_URI}\")\n",
    "else:\n",
    "    print(\"Creating NEW nanopub (not superseding any existing one)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "from rdflib import Dataset, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD, FOAF, PROV, DCTERMS as DCT\n",
    "\n",
    "# Namespaces\n",
    "NP = Namespace(\"http://www.nanopub.org/nschema#\")\n",
    "NPX = Namespace(\"http://purl.org/nanopub/x/\")\n",
    "NT = Namespace(\"https://w3id.org/np/o/ntemplate/\")\n",
    "ORCID = Namespace(\"https://orcid.org/\")\n",
    "SLV = Namespace(\"https://w3id.org/sciencelive/o/terms/\")\n",
    "\n",
    "# Template URIs\n",
    "SEARCH_EXECUTION_TEMPLATE = URIRef(\"https://w3id.org/np/RAV_H3udaSzxYOhhR0t-q7PKS6URwauD_Z5sMLbHmM2x0\")\n",
    "PROVENANCE_TEMPLATE = URIRef(\"https://w3id.org/np/RA7lSq6MuK_TIC6JMSHvLtee3lpLoZDOqLJCLXevnrPoU\")\n",
    "PUBINFO_TEMPLATE_1 = URIRef(\"https://w3id.org/np/RA0J4vUn_dekg-U1kK3AOEt02p9mT2WO03uGxLDec1jLw\")\n",
    "PUBINFO_TEMPLATE_2 = URIRef(\"https://w3id.org/np/RAukAcWHRDlkqxk7H2XNSegc1WnHI569INvNr-xdptDGI\")\n",
    "\n",
    "# Output directory\n",
    "output_dir = Path(\"./output\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Define Creation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function defined.\n"
     ]
    }
   ],
   "source": [
    "def create_search_execution_dataset_nanopub(config, db_search_uris, labels_map, supersedes_uri=None):\n",
    "    \"\"\"\n",
    "    Create a SearchExecutionDataset nanopublication.\n",
    "    \n",
    "    Template: RAV_H3udaSzxYOhhR0t-q7PKS6URwauD_Z5sMLbHmM2x0\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration dict\n",
    "        db_search_uris: List of /search URIs from published database search nanopubs\n",
    "        labels_map: Dict mapping URIs to labels\n",
    "        supersedes_uri: Optional URI of nanopub to supersede (for updates)\n",
    "    \"\"\"\n",
    "    TEMP_NP = Namespace(\"http://purl.org/nanopub/temp/np/\")\n",
    "    \n",
    "    ds = Dataset()\n",
    "    \n",
    "    # Bind namespaces\n",
    "    ds.bind(\"this\", \"http://purl.org/nanopub/temp/np/\")\n",
    "    ds.bind(\"sub\", TEMP_NP)\n",
    "    ds.bind(\"np\", NP)\n",
    "    ds.bind(\"dct\", DCT)\n",
    "    ds.bind(\"nt\", NT)\n",
    "    ds.bind(\"npx\", NPX)\n",
    "    ds.bind(\"xsd\", XSD)\n",
    "    ds.bind(\"rdfs\", RDFS)\n",
    "    ds.bind(\"orcid\", ORCID)\n",
    "    ds.bind(\"prov\", PROV)\n",
    "    ds.bind(\"foaf\", FOAF)\n",
    "    ds.bind(\"slv\", SLV)\n",
    "    \n",
    "    # URIs\n",
    "    np_uri = URIRef(\"http://purl.org/nanopub/temp/np/\")\n",
    "    head_uri = TEMP_NP.Head\n",
    "    assertion_uri = TEMP_NP.assertion\n",
    "    provenance_uri = TEMP_NP.provenance\n",
    "    pubinfo_uri = TEMP_NP.pubinfo\n",
    "    search_execution_uri = TEMP_NP.searchExecutionDataset\n",
    "    author_uri = ORCID[config['author']['orcid']]\n",
    "    \n",
    "    sed = config['search_execution_dataset']\n",
    "    \n",
    "    # HEAD\n",
    "    head = ds.graph(head_uri)\n",
    "    head.add((np_uri, RDF.type, NP.Nanopublication))\n",
    "    head.add((np_uri, NP.hasAssertion, assertion_uri))\n",
    "    head.add((np_uri, NP.hasProvenance, provenance_uri))\n",
    "    head.add((np_uri, NP.hasPublicationInfo, pubinfo_uri))\n",
    "    \n",
    "    # ASSERTION\n",
    "    assertion = ds.graph(assertion_uri)\n",
    "    assertion.add((search_execution_uri, RDF.type, SLV.SearchExecutionDataset))\n",
    "    assertion.add((search_execution_uri, RDFS.label, Literal(sed['label'])))\n",
    "    assertion.add((search_execution_uri, DCT.isPartOf, URIRef(sed['part_of'])))\n",
    "    assertion.add((search_execution_uri, DCT.created, Literal(sed['creation_date'], datatype=XSD.date)))\n",
    "    \n",
    "    # Reference database searches (external URIs)\n",
    "    for db_uri in db_search_uris:\n",
    "        assertion.add((search_execution_uri, SLV.includesDbSearch, URIRef(db_uri)))\n",
    "    \n",
    "    # Methodologies\n",
    "    assertion.add((search_execution_uri, SLV.usesDeduplicationMethodology, Literal(sed['deduplication_methodology'])))\n",
    "    assertion.add((search_execution_uri, SLV.usesReviewMethodology, Literal(sed['review_methodology'])))\n",
    "    assertion.add((search_execution_uri, SLV.usesScreeningMethodology, Literal(sed['screening_methodology'])))\n",
    "    \n",
    "    # Counts\n",
    "    assertion.add((search_execution_uri, SLV.hasScreenedRecordCount, Literal(sed['screened_record_count'])))\n",
    "    assertion.add((search_execution_uri, SLV.hasFulltextScreenedRecordCount, Literal(sed['fulltext_screened_record_count'])))\n",
    "    assertion.add((search_execution_uri, SLV.hasFinalIncludedStudyCount, Literal(sed['final_included_study_count'])))\n",
    "    assertion.add((search_execution_uri, SLV.hasExclusionBreakdown, Literal(sed['exclusion_breakdown'])))\n",
    "    \n",
    "    # Dataset file location (REQUIRED)\n",
    "    if sed.get('dataset_file_location'):\n",
    "        assertion.add((search_execution_uri, SLV.hasDatasetFileLocation, URIRef(sed['dataset_file_location'])))\n",
    "    else:\n",
    "        assertion.add((search_execution_uri, SLV.hasDatasetFileLocation, URIRef(\"https://zenodo.org/records/PLACEHOLDER\")))\n",
    "        print(\"⚠️  Warning: dataset_file_location empty, using placeholder\")\n",
    "    \n",
    "    # Limitations (optional)\n",
    "    if sed.get('limitations'):\n",
    "        assertion.add((search_execution_uri, SLV.hasLimitations, Literal(sed['limitations'])))\n",
    "    \n",
    "    # PROVENANCE\n",
    "    provenance = ds.graph(provenance_uri)\n",
    "    provenance.add((assertion_uri, PROV.wasAttributedTo, author_uri))\n",
    "    \n",
    "    # PUBINFO\n",
    "    pubinfo = ds.graph(pubinfo_uri)\n",
    "    pubinfo.add((author_uri, FOAF.name, Literal(config['author']['name'])))\n",
    "    \n",
    "    now = datetime.now(timezone.utc).isoformat()\n",
    "    pubinfo.add((np_uri, DCT.created, Literal(now, datatype=XSD.dateTime)))\n",
    "    pubinfo.add((np_uri, DCT.creator, author_uri))\n",
    "    pubinfo.add((np_uri, DCT.license, URIRef(\"https://creativecommons.org/licenses/by/4.0/\")))\n",
    "    pubinfo.add((np_uri, RDFS.label, Literal(sed['label'][:50] + \"...\")))\n",
    "    pubinfo.add((np_uri, NPX.introduces, search_execution_uri))\n",
    "    pubinfo.add((np_uri, NPX.wasCreatedAt, URIRef(\"https://nanodash.knowledgepixels.com/\")))\n",
    "    \n",
    "    # SUPERSEDES - if updating an existing nanopub\n",
    "    if supersedes_uri:\n",
    "        pubinfo.add((np_uri, NPX.supersedes, URIRef(supersedes_uri)))\n",
    "        print(f\"✓ Will supersede: {supersedes_uri}\")\n",
    "    \n",
    "    # Template references\n",
    "    pubinfo.add((np_uri, NT.wasCreatedFromTemplate, SEARCH_EXECUTION_TEMPLATE))\n",
    "    pubinfo.add((np_uri, NT.wasCreatedFromProvenanceTemplate, PROVENANCE_TEMPLATE))\n",
    "    pubinfo.add((np_uri, NT.wasCreatedFromPubinfoTemplate, PUBINFO_TEMPLATE_1))\n",
    "    pubinfo.add((np_uri, NT.wasCreatedFromPubinfoTemplate, PUBINFO_TEMPLATE_2))\n",
    "    \n",
    "    # Labels for referenced searches (CRITICAL for Nanodash display!)\n",
    "    for uri, label in labels_map.items():\n",
    "        pubinfo.add((URIRef(uri), NT.hasLabelFromApi, Literal(label)))\n",
    "    \n",
    "    return ds\n",
    "\n",
    "print(\"Function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Generate Search Execution Dataset Nanopub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Will supersede: https://w3id.org/np/RAMPy96eCLCXlGR9VvCVf6rJmpN_DlxxarMGm91_5n-O8\n",
      "\n",
      "✓ Created: quantum-biodiversity-search-execution-update.unsigned.trig\n",
      "  References 6 database searches\n",
      "  Supersedes: https://w3id.org/np/RAMPy96eCLCXlGR9VvCVf6rJmpN_DlxxarMGm91_5n-O8\n",
      "  Path: /Users/annef/Documents/FAIR2Adapt/systematic-review-pipeline/notebooks/output/quantum-biodiversity-search-execution-update.unsigned.trig\n"
     ]
    }
   ],
   "source": [
    "if not DB_SEARCH_URIS:\n",
    "    print(\"❌ No database search URIs available.\")\n",
    "    print(\"Please complete Step 1 first.\")\n",
    "else:\n",
    "    # Create the nanopub\n",
    "    sed_dataset = create_search_execution_dataset_nanopub(\n",
    "        config=config,\n",
    "        db_search_uris=DB_SEARCH_URIS,\n",
    "        labels_map=LABELS_MAP,\n",
    "        supersedes_uri=SUPERSEDES_URI\n",
    "    )\n",
    "    \n",
    "    # Save unsigned\n",
    "    suffix = \"-update\" if SUPERSEDES_URI else \"\"\n",
    "    filename = f\"{config['output']['filename']}{suffix}.unsigned.trig\"\n",
    "    filepath = output_dir / filename\n",
    "    sed_dataset.serialize(destination=str(filepath), format='trig')\n",
    "    \n",
    "    print(f\"\\n✓ Created: {filename}\")\n",
    "    print(f\"  References {len(DB_SEARCH_URIS)} database searches\")\n",
    "    if SUPERSEDES_URI:\n",
    "        print(f\"  Supersedes: {SUPERSEDES_URI}\")\n",
    "    print(f\"  Path: {filepath.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Sign and Publish\n",
    "\n",
    "**Set `PUBLISH = True` when ready.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profile: Anne Fouilloux\n",
      "Test server: False\n",
      "✓ Signed\n",
      "✓ Saved: output/quantum-biodiversity-search-execution-update.unsigned.signed.trig\n",
      "✓ Published\n",
      "\n",
      "============================================================\n",
      "SEARCH EXECUTION DATASET UPDATED\n",
      "============================================================\n",
      "New URI: https://w3id.org/np/RAhFlAUVte1zioZDIBXyg6GdSziwLxgqwxPkDi7v110WU\n",
      "Supersedes: https://w3id.org/np/RAMPy96eCLCXlGR9VvCVf6rJmpN_DlxxarMGm91_5n-O8\n",
      "\n",
      "View in Nanodash:\n",
      "https://nanodash.knowledgepixels.com/explore?id=https://w3id.org/np/RAhFlAUVte1zioZDIBXyg6GdSziwLxgqwxPkDi7v110WU\n"
     ]
    }
   ],
   "source": [
    "PUBLISH = True          # ← Set to True when ready\n",
    "USE_TEST_SERVER = False   # ← Set to False for production\n",
    "\n",
    "if PUBLISH and DB_SEARCH_URIS:\n",
    "    from nanopub import Nanopub, NanopubConf, load_profile\n",
    "    \n",
    "    profile = load_profile()\n",
    "    print(f\"Profile: {profile.name}\")\n",
    "    print(f\"Test server: {USE_TEST_SERVER}\")\n",
    "    \n",
    "    conf = NanopubConf(profile=profile, use_test_server=USE_TEST_SERVER)\n",
    "    \n",
    "    np_obj = Nanopub(rdf=filepath, conf=conf)\n",
    "    np_obj.sign()\n",
    "    print(\"✓ Signed\")\n",
    "    \n",
    "    signed_path = filepath.with_suffix('.signed.trig')\n",
    "    np_obj.store(signed_path)\n",
    "    print(f\"✓ Saved: {signed_path}\")\n",
    "    \n",
    "    np_obj.publish()\n",
    "    print(f\"✓ Published\")\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    if SUPERSEDES_URI:\n",
    "        print(\"SEARCH EXECUTION DATASET UPDATED\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"New URI: {np_obj.source_uri}\")\n",
    "        print(f\"Supersedes: {SUPERSEDES_URI}\")\n",
    "    else:\n",
    "        print(\"SEARCH EXECUTION DATASET PUBLISHED\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"URI: {np_obj.source_uri}\")\n",
    "    \n",
    "    print(f\"\\nView in Nanodash:\")\n",
    "    print(f\"https://nanodash.knowledgepixels.com/explore?id={np_obj.source_uri}\")\n",
    "\n",
    "elif not DB_SEARCH_URIS:\n",
    "    print(\"❌ Cannot publish: No database search URIs\")\n",
    "else:\n",
    "    print(\"Publishing disabled. Set PUBLISH = True when ready.\")\n",
    "    print(f\"\\nFile created: {filepath}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "### Superseding Explained\n",
    "\n",
    "Nanopublications are **immutable** - once published, they cannot be modified. However, you can create a new version that **supersedes** the old one by adding:\n",
    "\n",
    "```turtle\n",
    "sub:pubinfo {\n",
    "    this: npx:supersedes <https://w3id.org/np/OLD_NANOPUB_URI> .\n",
    "}\n",
    "```\n",
    "\n",
    "When you supersede a nanopub:\n",
    "- The old nanopub remains accessible but is marked as outdated\n",
    "- Queries and indexes will return the new version\n",
    "- The version history is preserved\n",
    "\n",
    "### Why This Update Was Needed\n",
    "\n",
    "Your original nanopub `RAMPy96eCLCXlGR9VvCVf6rJmpN_DlxxarMGm91_5n-O8` used **inline** database search definitions:\n",
    "\n",
    "```turtle\n",
    "# ❌ Original (inline resources don't display in Nanodash)\n",
    "sub:searchExecutionDataset slv:includesDbSearch sub:dbSearch1 .\n",
    "sub:dbSearch1 rdfs:label \"OpenAlex\" .\n",
    "```\n",
    "\n",
    "The template expects **external URI references**:\n",
    "\n",
    "```turtle\n",
    "# ✅ Correct (references published nanopubs)\n",
    "sub:searchExecutionDataset slv:includesDbSearch <https://w3id.org/np/RAxxxx/search> .\n",
    "```\n",
    "\n",
    "This new nanopub will supersede the old one with proper external references."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
