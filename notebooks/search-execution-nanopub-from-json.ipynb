{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRISMA Search Execution Dataset Nanopublication Generator\n",
    "\n",
    "This notebook generates a nanopublication for documenting search execution and results following PRISMA 2020 guidelines.\n",
    "\n",
    "**Template:** [Declaring a PRISMA search execution dataset](https://w3id.org/np/RAV_H3udaSzxYOhhR0t-q7PKS6URwauD_Z5sMLbHmM2x0) by Tobias Kuhn (2025-11-21)\n",
    "\n",
    "## Workflow Position\n",
    "1. PICO Research Question ✅\n",
    "2. Search Strategy ✅\n",
    "3. **Search Execution Dataset** ← This notebook\n",
    "4. Study Inclusion\n",
    "5. Study Assessment Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configuration\n",
    "\n",
    "Set the path to your JSON configuration file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your JSON configuration file\n",
    "SEARCH_EXECUTION_FILE = \"../inputs/search-execution-quantum-biodiversity_updated.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configuration for: Quantum Computing for Biodiversity - Search Execution Results\n",
      "Author: Anne Fouilloux (0000-0002-1784-2920)\n",
      "Part of: https://w3id.org/np/RA8B3ptXUOsN7obpkFGtA0FBmsh0OnID53wOsUIpSKTcg\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "with open(SEARCH_EXECUTION_FILE, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(f\"Loaded configuration for: {config['search_execution_dataset']['label']}\")\n",
    "print(f\"Author: {config['author']['name']} ({config['author']['orcid']})\")\n",
    "print(f\"Part of: {config['search_execution_dataset']['part_of']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setup Namespaces and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespaces configured.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "from rdflib import Graph, Dataset, Namespace, URIRef, Literal, BNode\n",
    "from rdflib.namespace import RDF, RDFS, XSD, FOAF, PROV, DCTERMS as DCT\n",
    "\n",
    "# Define namespaces\n",
    "NP = Namespace(\"http://www.nanopub.org/nschema#\")\n",
    "NPX = Namespace(\"http://purl.org/nanopub/x/\")\n",
    "NT = Namespace(\"https://w3id.org/np/o/ntemplate/\")\n",
    "ORCID = Namespace(\"https://orcid.org/\")\n",
    "SLV = Namespace(\"https://w3id.org/sciencelive/o/terms/\")\n",
    "\n",
    "# Temporary namespace for building (will be replaced when signed)\n",
    "TEMP_NP = Namespace(\"http://purl.org/nanopub/temp/np/\")\n",
    "\n",
    "# Template URIs\n",
    "SEARCH_EXECUTION_TEMPLATE = URIRef(\"https://w3id.org/np/RAV_H3udaSzxYOhhR0t-q7PKS6URwauD_Z5sMLbHmM2x0\")\n",
    "PROVENANCE_TEMPLATE = URIRef(\"https://w3id.org/np/RA7lSq6MuK_TIC6JMSHvLtee3lpLoZDOqLJCLXevnrPoU\")\n",
    "PUBINFO_TEMPLATE_1 = URIRef(\"https://w3id.org/np/RA0J4vUn_dekg-U1kK3AOEt02p9mT2WO03uGxLDec1jLw\")\n",
    "PUBINFO_TEMPLATE_2 = URIRef(\"https://w3id.org/np/RAukAcWHRDlkqxk7H2XNSegc1WnHI569INvNr-xdptDGI\")\n",
    "\n",
    "print(\"Namespaces configured.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Build the Nanopublication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized with namespace bindings.\n"
     ]
    }
   ],
   "source": [
    "# Create Dataset with all namespace bindings\n",
    "ds = Dataset()\n",
    "ds.bind(\"this\", \"http://purl.org/nanopub/temp/np/\")\n",
    "ds.bind(\"sub\", TEMP_NP)\n",
    "ds.bind(\"np\", NP)\n",
    "ds.bind(\"dct\", DCT)\n",
    "ds.bind(\"nt\", NT)\n",
    "ds.bind(\"npx\", NPX)\n",
    "ds.bind(\"xsd\", XSD)\n",
    "ds.bind(\"rdfs\", RDFS)\n",
    "ds.bind(\"orcid\", ORCID)\n",
    "ds.bind(\"prov\", PROV)\n",
    "ds.bind(\"foaf\", FOAF)\n",
    "ds.bind(\"slv\", SLV)\n",
    "\n",
    "# URIs for nanopub structure\n",
    "np_uri = URIRef(\"http://purl.org/nanopub/temp/np/\")\n",
    "head_uri = TEMP_NP.Head\n",
    "assertion_uri = TEMP_NP.assertion\n",
    "provenance_uri = TEMP_NP.provenance\n",
    "pubinfo_uri = TEMP_NP.pubinfo\n",
    "\n",
    "# Main resource URI\n",
    "search_execution_uri = TEMP_NP.searchExecutionDataset\n",
    "\n",
    "# Author ORCID\n",
    "author_uri = ORCID[config['author']['orcid']]\n",
    "\n",
    "print(\"Dataset initialized with namespace bindings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head graph created.\n"
     ]
    }
   ],
   "source": [
    "# HEAD graph\n",
    "head = ds.graph(head_uri)\n",
    "head.add((np_uri, RDF.type, NP.Nanopublication))\n",
    "head.add((np_uri, NP.hasAssertion, assertion_uri))\n",
    "head.add((np_uri, NP.hasProvenance, provenance_uri))\n",
    "head.add((np_uri, NP.hasPublicationInfo, pubinfo_uri))\n",
    "\n",
    "print(\"Head graph created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assertion graph created with 60 triples.\n"
     ]
    }
   ],
   "source": [
    "# ASSERTION graph\n",
    "assertion = ds.graph(assertion_uri)\n",
    "sed = config['search_execution_dataset']\n",
    "\n",
    "# Type\n",
    "assertion.add((search_execution_uri, RDF.type, SLV.SearchExecutionDataset))\n",
    "\n",
    "# Label\n",
    "assertion.add((search_execution_uri, RDFS.label, Literal(sed['label'])))\n",
    "\n",
    "# Part of (links to PICO/systematic review)\n",
    "assertion.add((search_execution_uri, DCT.isPartOf, URIRef(sed['part_of'])))\n",
    "\n",
    "# Creation date\n",
    "assertion.add((search_execution_uri, DCT.created, Literal(sed['creation_date'], datatype=XSD.date)))\n",
    "\n",
    "# Database searches (repeatable)\n",
    "# Handle both formats: list of URIs OR list of objects with search details\n",
    "for idx, db_search in enumerate(sed.get('db_searches', [])):\n",
    "    if isinstance(db_search, str):\n",
    "        # Simple URI format\n",
    "        if db_search:\n",
    "            assertion.add((search_execution_uri, SLV.includesDbSearch, URIRef(db_search)))\n",
    "    elif isinstance(db_search, dict):\n",
    "        # Rich object format - create a blank node for each search\n",
    "        search_node = TEMP_NP[f\"dbSearch{idx+1}\"]\n",
    "        assertion.add((search_execution_uri, SLV.includesDbSearch, search_node))\n",
    "        \n",
    "        if db_search.get('database_url'):\n",
    "            assertion.add((search_node, SLV.hasDatabase, URIRef(db_search['database_url'])))\n",
    "        if db_search.get('database_label'):\n",
    "            assertion.add((search_node, RDFS.label, Literal(db_search['database_label'])))\n",
    "        if db_search.get('search_query'):\n",
    "            assertion.add((search_node, SLV.hasSearchQuery, Literal(db_search['search_query'])))\n",
    "        if db_search.get('filters'):\n",
    "            assertion.add((search_node, SLV.hasFilters, Literal(db_search['filters'])))\n",
    "        if db_search.get('results_count') is not None:\n",
    "            assertion.add((search_node, SLV.hasResultsCount, Literal(str(db_search['results_count']))))\n",
    "        if db_search.get('export_format'):\n",
    "            assertion.add((search_node, SLV.hasExportFormat, Literal(db_search['export_format'])))\n",
    "        if db_search.get('notes'):\n",
    "            assertion.add((search_node, RDFS.comment, Literal(db_search['notes'])))\n",
    "\n",
    "# Deduplication methodology\n",
    "if sed.get('deduplication_methodology'):\n",
    "    assertion.add((search_execution_uri, SLV.usesDeduplicationMethodology, Literal(sed['deduplication_methodology'])))\n",
    "\n",
    "# Review methodology\n",
    "if sed.get('review_methodology'):\n",
    "    assertion.add((search_execution_uri, SLV.usesReviewMethodology, Literal(sed['review_methodology'])))\n",
    "\n",
    "# Screening methodology\n",
    "if sed.get('screening_methodology'):\n",
    "    assertion.add((search_execution_uri, SLV.usesScreeningMethodology, Literal(sed['screening_methodology'])))\n",
    "\n",
    "# Record counts\n",
    "if sed.get('screened_record_count'):\n",
    "    assertion.add((search_execution_uri, SLV.hasScreenedRecordCount, Literal(sed['screened_record_count'])))\n",
    "\n",
    "if sed.get('fulltext_screened_record_count'):\n",
    "    assertion.add((search_execution_uri, SLV.hasFulltextScreenedRecordCount, Literal(sed['fulltext_screened_record_count'])))\n",
    "\n",
    "if sed.get('final_included_study_count'):\n",
    "    assertion.add((search_execution_uri, SLV.hasFinalIncludedStudyCount, Literal(sed['final_included_study_count'])))\n",
    "\n",
    "# Exclusion breakdown\n",
    "if sed.get('exclusion_breakdown'):\n",
    "    assertion.add((search_execution_uri, SLV.hasExclusionBreakdown, Literal(sed['exclusion_breakdown'])))\n",
    "\n",
    "# Dataset file location\n",
    "if sed.get('dataset_file_location') and sed['dataset_file_location'].strip():\n",
    "    assertion.add((search_execution_uri, SLV.hasDatasetFileLocation, URIRef(sed['dataset_file_location'])))\n",
    "\n",
    "# Limitations (optional)\n",
    "if sed.get('limitations'):\n",
    "    assertion.add((search_execution_uri, SLV.hasLimitations, Literal(sed['limitations'])))\n",
    "\n",
    "print(f\"Assertion graph created with {len(assertion)} triples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provenance graph created.\n"
     ]
    }
   ],
   "source": [
    "# PROVENANCE graph\n",
    "provenance = ds.graph(provenance_uri)\n",
    "provenance.add((assertion_uri, PROV.wasAttributedTo, author_uri))\n",
    "\n",
    "print(\"Provenance graph created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pubinfo graph created with 11 triples.\n"
     ]
    }
   ],
   "source": [
    "# PUBINFO graph\n",
    "pubinfo = ds.graph(pubinfo_uri)\n",
    "\n",
    "# Author info\n",
    "pubinfo.add((author_uri, FOAF.name, Literal(config['author']['name'])))\n",
    "\n",
    "# Nanopub metadata\n",
    "timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n",
    "pubinfo.add((np_uri, DCT.created, Literal(timestamp, datatype=XSD.dateTime)))\n",
    "pubinfo.add((np_uri, DCT.creator, author_uri))\n",
    "pubinfo.add((np_uri, DCT.license, URIRef(\"https://creativecommons.org/licenses/by/4.0/\")))\n",
    "\n",
    "# Introduces the search execution dataset\n",
    "pubinfo.add((np_uri, NPX.introduces, search_execution_uri))\n",
    "\n",
    "# Created at Nanodash\n",
    "pubinfo.add((np_uri, NPX.wasCreatedAt, URIRef(\"https://nanodash.knowledgepixels.com/\")))\n",
    "\n",
    "# Label for the nanopub (truncated to ~50 chars)\n",
    "label = sed['label'][:50] + \"...\" if len(sed['label']) > 50 else sed['label']\n",
    "pubinfo.add((np_uri, RDFS.label, Literal(label)))\n",
    "\n",
    "# Template references\n",
    "pubinfo.add((np_uri, NT.wasCreatedFromTemplate, SEARCH_EXECUTION_TEMPLATE))\n",
    "pubinfo.add((np_uri, NT.wasCreatedFromProvenanceTemplate, PROVENANCE_TEMPLATE))\n",
    "pubinfo.add((np_uri, NT.wasCreatedFromPubinfoTemplate, PUBINFO_TEMPLATE_1))\n",
    "pubinfo.add((np_uri, NT.wasCreatedFromPubinfoTemplate, PUBINFO_TEMPLATE_2))\n",
    "\n",
    "print(f\"Pubinfo graph created with {len(pubinfo)} triples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Serialize and Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nanopub saved to: quantum-biodiversity-search-execution.trig\n",
      "File size: 6879 bytes\n"
     ]
    }
   ],
   "source": [
    "# Serialize to TriG format\n",
    "output_filename = config['output']['filename'] + \".trig\"\n",
    "output_path = Path(output_filename)\n",
    "\n",
    "trig_output = ds.serialize(format='trig')\n",
    "output_path.write_text(trig_output)\n",
    "\n",
    "print(f\"Nanopub saved to: {output_path}\")\n",
    "print(f\"File size: {output_path.stat().st_size} bytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Generated TriG:\n",
      "============================================================\n",
      "@prefix dct: <http://purl.org/dc/terms/> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix np: <http://www.nanopub.org/nschema#> .\n",
      "@prefix npx: <http://purl.org/nanopub/x/> .\n",
      "@prefix nt: <https://w3id.org/np/o/ntemplate/> .\n",
      "@prefix orcid: <https://orcid.org/> .\n",
      "@prefix prov: <http://www.w3.org/ns/prov#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix slv: <https://w3id.org/sciencelive/o/terms/> .\n",
      "@prefix sub: <http://purl.org/nanopub/temp/np/> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "sub:provenance {\n",
      "    sub:assertion prov:wasAttributedTo orcid:0000-0002-1784-2920 .\n",
      "}\n",
      "\n",
      "sub:assertion {\n",
      "    sub:searchExecutionDataset a slv:SearchExecutionDataset ;\n",
      "        rdfs:label \"Quantum Computing for Biodiversity - Search Execution Results\" ;\n",
      "        dct:created \"2025-12-26\"^^xsd:date ;\n",
      "        dct:isPartOf <https://w3id.org/np/RA8B3ptXUOsN7obpkFGtA0FBmsh0OnID53wOsUIpSKTcg> ;\n",
      "        slv:hasExclusionBreakdown \"Title/abstract exclusions: Not about quantum computing (XXX), Not about biodiversity/conservation (XXX), Not primary research (XXX). Full-text exclusions: Full text not available (XXX), Not in English (XXX), Outside date range (XXX), Other (XXX).\" ;\n",
      "        slv:hasFinalIncludedStudyCount \"XXX\" ;\n",
      "        slv:hasFulltextScreenedRecordCount \"XXX\" ;\n",
      "        slv:hasLimitations \"Limitations: (1) Scopus and Web of Science replaced with OpenAlex and Semantic Scholar due to subscription access requirements - OpenAlex provides comparable bibliographic coverage, (2) IEEE Xplore restricted to Open Access content only due to paywall constraints - may underrepresent paywalled IEEE conference proceedings, (3) Emerging field with inconsistent terminology may affect recall, (4) Grey literature (technical reports, working papers) not systematically searched.\" ;\n",
      "        slv:hasScreenedRecordCount \"1616\" ;\n",
      "        slv:includesDbSearch sub:dbSearch1,\n",
      "            sub:dbSearch2,\n",
      "            sub:dbSearch3,\n",
      "            sub:dbSearch4,\n",
      "            sub:dbSearch5,\n",
      "            sub:dbSearch6 ;\n",
      "        slv:usesDeduplicationMethodology \"Records from all 6 databases combined using Zotero. Automatic deduplication on DOI and title fields. Manual review of potential duplicates (similar titles, matching authors). Expected high overlap between OpenAlex, Semantic Scholar, and PubMed.\" ;\n",
      "        slv:usesReviewMethodology \"Single reviewer screening with validation by second reviewer on 20% sample given emerging interdisciplinary nature of the topic.\" ;\n",
      "        slv:usesScreeningMethodology \"Two-stage screening: (1) Title and abstract screening against PICO criteria - must address quantum computing methods AND biodiversity/conservation applications, (2) Full-text review for methodological rigor and relevance. Exclusions: opinion pieces, editorials without methods, theoretical quantum physics without biological application.\" .\n",
      "\n",
      "    sub:dbSearch1 rdfs:label \"OpenAlex\" ;\n",
      "        rdfs:comment \"Best free replacement for Scopus/WoS\" ;\n",
      "        slv:hasDatabase <https://openalex.org/> ;\n",
      "        slv:hasExportFormat \"BibTeX\" ;\n",
      "        slv:hasFilters \"2015-2025\" ;\n",
      "        slv:hasResultsCount \"467\" ;\n",
      "        slv:hasSearchQuery \"(quantum computing OR quantum machine learning OR QML OR QAOA OR quantum annealing) AND (biodiversity OR conservation OR species distribution OR ecological network OR population genetics)\" .\n",
      "\n",
      "    sub:dbSearch2 rdfs:label \"arXiv\" ;\n",
      "        rdfs:comment \"Essential for quantum computing preprints\" ;\n",
      "        slv:hasDatabase <https://arxiv.org/> ;\n",
      "        slv:hasExportFormat \"BibTeX\" ;\n",
      "        slv:hasFilters \"2015-2025; Categories: quant-ph, cs.LG, cs.AI, q-bio\" ;\n",
      "        slv:hasResultsCount \"178\" ;\n",
      "        slv:hasSearchQuery \"(quantum computing OR quantum machine learning OR QML OR QAOA OR quantum annealing) AND (biodiversity OR conservation OR species distribution OR ecological network OR population genetics)\" .\n",
      "\n",
      "    sub:dbSearch3 rdfs:label \"Semantic Scholar\" ;\n",
      "        rdfs:comment \"AI-enhanced search\" ;\n",
      "        slv:hasDatabase <https://www.semanticscholar.org/> ;\n",
      "        slv:hasExportFormat \"BibTeX\" ;\n",
      "        slv:hasFilters \"2015-2025; Fields: CS, Biology, Environmental Science\" ;\n",
      "        slv:hasResultsCount \"621\" ;\n",
      "        slv:hasSearchQuery \"quantum computing biodiversity conservation species distribution\" .\n",
      "\n",
      "    sub:dbSearch4 rdfs:label \"PubMed\" ;\n",
      "        rdfs:comment \"Biomedical focus\" ;\n",
      "        slv:hasDatabase <https://pubmed.ncbi.nlm.nih.gov/> ;\n",
      "        slv:hasExportFormat \"RIS/NBIB\" ;\n",
      "        slv:hasFilters \"2015-present; English\" ;\n",
      "        slv:hasResultsCount \"4\" ;\n",
      "        slv:hasSearchQuery \"(quantum computing[Title/Abstract] OR quantum machine learning[Title/Abstract] OR quantum annealing[Title/Abstract]) AND (biodiversity[Title/Abstract] OR conservation[Title/Abstract] OR species distribution[Title/Abstract] OR population genetics[Title/Abstract])\" .\n",
      "\n",
      "    sub:dbSearch5 rdfs:label \"IEEE Xplore (OA only)\" ;\n",
      "        rdfs:comment \"OA content only due to paywall\" ;\n",
      "        slv:hasDatabase <https://ieeexplore.ieee.org/> ;\n",
      "        slv:hasExportFormat \"RIS\" ;\n",
      "        slv:hasFilters \"2015-2025; Open Access Only\" ;\n",
      "        slv:hasResultsCount \"0\" ;\n",
      "        slv:hasSearchQuery \"(\\\"quantum computing\\\" OR \\\"quantum machine learning\\\" OR \\\"QML\\\" OR \\\"QAOA\\\" OR \\\"quantum annealing\\\") AND (\\\"biodiversity\\\" OR \\\"conservation\\\" OR \\\"species distribution\\\" OR \\\"ecological network\\\" OR \\\"population genetics\\\")\" .\n",
      "\n",
      "    sub:dbSearch6 rdfs:label \"Europe PMC\" ;\n",
      "        rdfs:comment \"Complements PubMed with European repository content\" ;\n",
      "        slv:hasDatabase <https://europepmc.org/> ;\n",
      "        slv:hasExportFormat \"RIS\" ;\n",
      "        slv:hasFilters \"2015-2025; Open Access\" ;\n",
      "        slv:hasResultsCount \"597\" ;\n",
      "        slv:hasSearchQuery \"(quantum computing OR quantum machine learning) AND (biodiversity OR conservation OR species distribution)\" .\n",
      "}\n",
      "\n",
      "sub:Head {\n",
      "    sub: a np:Nanopublication ;\n",
      "        np:hasAssertion sub:assertion ;\n",
      "        np:hasProvenance sub:provenance ;\n",
      "        np:hasPublicationInfo sub:pubinfo .\n",
      "}\n",
      "\n",
      "sub:pubinfo {\n",
      "    sub: rdfs:label \"Quantum Computing for Biodiversity - Search Execut...\" ;\n",
      "        dct:created \"2025-12-26T18:40:02.181000+00:00\"^^xsd:dateTime ;\n",
      "        dct:creator orcid:0000-0002-1784-2920 ;\n",
      "        dct:license <https://creativecommons.org/licenses/by/4.0/> ;\n",
      "        npx:introduces sub:searchExecutionDataset ;\n",
      "        npx:wasCreatedAt <https://nanodash.knowledgepixels.com/> ;\n",
      "        nt:wasCreatedFromProvenanceTemplate <https://w3id.org/np/RA7lSq6MuK_TIC6JMSHvLtee3lpLoZDOqLJCLXevnrPoU> ;\n",
      "        nt:wasCreatedFromPubinfoTemplate <https://w3id.org/np/RA0J4vUn_dekg-U1kK3AOEt02p9mT2WO03uGxLDec1jLw>,\n",
      "            <https://w3id.org/np/RAukAcWHRDlkqxk7H2XNSegc1WnHI569INvNr-xdptDGI> ;\n",
      "        nt:wasCreatedFromTemplate <https://w3id.org/np/RAV_H3udaSzxYOhhR0t-q7PKS6URwauD_Z5sMLbHmM2x0> .\n",
      "\n",
      "    orcid:0000-0002-1784-2920 foaf:name \"Anne Fouilloux\" .\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the generated TriG\n",
    "print(\"=\" * 60)\n",
    "print(\"Generated TriG:\")\n",
    "print(\"=\" * 60)\n",
    "print(trig_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Validate (Optional)\n",
    "\n",
    "Load the generated file to verify it can be parsed by the nanopub library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Nanopub RDF structure is valid!\n",
      "   Assertion triples: 60\n",
      "   Provenance triples: 1\n",
      "   Pubinfo triples: 11\n"
     ]
    }
   ],
   "source": [
    "from nanopub import Nanopub, NanopubConf, load_profile\n",
    "\n",
    "# Load and validate (without signing)\n",
    "try:\n",
    "    # Just load to check RDF structure is valid\n",
    "    np_obj = Nanopub(rdf=output_path)\n",
    "    print(\"✅ Nanopub RDF structure is valid!\")\n",
    "    print(f\"   Assertion triples: {len(np_obj.assertion)}\")\n",
    "    print(f\"   Provenance triples: {len(np_obj.provenance)}\")\n",
    "    print(f\"   Pubinfo triples: {len(np_obj.pubinfo)}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Validation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Sign and Publish (Optional)\n",
    "\n",
    "Uncomment to sign and publish:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded profile: Anne Fouilloux\n",
      "✓ Signed\n",
      "✓ Saved: quantum-biodiversity-search-execution.signed.trig\n",
      "✓ Published: https://w3id.org/np/RAMPy96eCLCXlGR9VvCVf6rJmpN_DlxxarMGm91_5n-O8\n"
     ]
    }
   ],
   "source": [
    "# Sign and Publish\n",
    "PUBLISH = True\n",
    "USE_TEST_SERVER = False\n",
    "\n",
    "if PUBLISH:\n",
    "    from nanopub import Nanopub, NanopubConf, load_profile\n",
    "    \n",
    "    profile = load_profile()\n",
    "    print(f\"Loaded profile: {profile.name}\")\n",
    "    \n",
    "    conf = NanopubConf(profile=profile, use_test_server=USE_TEST_SERVER)\n",
    "    np_obj = Nanopub(rdf=output_path, conf=conf)\n",
    "    \n",
    "    np_obj.sign()\n",
    "    print(f\"✓ Signed\")\n",
    "    \n",
    "    signed_path = Path(f\"{config['output']['filename']}.signed.trig\")\n",
    "    np_obj.store(signed_path)\n",
    "    print(f\"✓ Saved: {signed_path}\")\n",
    "    \n",
    "    np_obj.publish()\n",
    "    print(f\"✓ Published: {np_obj.source_uri}\")\n",
    "else:\n",
    "    print(\"Publishing disabled. Set PUBLISH = True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## JSON Configuration Schema\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"author\": {\n",
    "    \"orcid\": \"0000-0002-1784-2920\",\n",
    "    \"name\": \"Anne Fouilloux\"\n",
    "  },\n",
    "  \"search_execution_dataset\": {\n",
    "    \"label\": \"My Search Execution Dataset\",\n",
    "    \"part_of\": \"https://w3id.org/np/...\",  // URI of PICO/systematic review\n",
    "    \"creation_date\": \"2025-01-31\",  // Date search was completed\n",
    "    \"db_searches\": [  // URIs to database search nanopubs (optional, repeatable)\n",
    "      \"https://w3id.org/np/.../search\"\n",
    "    ],\n",
    "    \"deduplication_methodology\": \"Description of deduplication process\",\n",
    "    \"review_methodology\": \"Number of reviewers, independence, disagreement resolution\",\n",
    "    \"screening_methodology\": \"Title/abstract and full-text screening methods\",\n",
    "    \"screened_record_count\": \"1000\",  // Total records screened\n",
    "    \"fulltext_screened_record_count\": \"200\",  // Records at full-text stage\n",
    "    \"final_included_study_count\": \"50\",  // Final included studies\n",
    "    \"exclusion_breakdown\": \"Exclusion reasons with counts\",\n",
    "    \"dataset_file_location\": \"https://zenodo.org/...\",  // URL to deposited data\n",
    "    \"limitations\": \"Optional: search limitations and notes\"  // Optional\n",
    "  },\n",
    "  \"output\": {\n",
    "    \"filename\": \"my-search-execution\"  // .trig will be appended\n",
    "  }\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
