{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PICO Research Question Nanopublication Creator\n",
    "\n",
    "Creates PICO nanopublications from a JSON configuration file.\n",
    "\n",
    "**Template:** [Defining a PICO-based research question](https://w3id.org/np/RA5e5XeXy_-aNK5giB7kBAEQslTLVydHeM4YYEzhmEE2w)\n",
    "\n",
    "This template uses the Cochrane PICO ontology for structured research questions.\n",
    "\n",
    "---\n",
    "\n",
    "## Instructions\n",
    "\n",
    "1. **Create a JSON file** with your PICO details (see template below)\n",
    "2. **Set the path** to your JSON file in Section 1\n",
    "3. **Run All Cells** ‚Üí Get your `.trig` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìÅ SECTION 1: INPUT FILE (EDIT THIS)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your PICO JSON file\n",
    "PICO_FILE = \"../inputs/quantum-biodiversity/pico-quantum-biodiversity.json\"\n",
    "PICO_FILE = \"../inputs/pets-biodiversity/pets-biodiversity-pico.json\"\n",
    "PICO_FILE = \"../inputs/agriculture-privacy-eo/pico-agriculture-privacy-eo.json\"\n",
    "PICO_FILE = \"../inputs/climate-differential-privacy/pico-climate-differential-privacy.json\"\n",
    "PICO_FILE = \"../inputs/crossborder-eo-privacy/pico-crossborder-eo-privacy.json\"\n",
    "PICO_FILE = \"../inputs/federated-learning-eo/pico-federated-learning-eo.json\"\n",
    "PICO_FILE = \"../inputs/indigenous-forest-privacy/pico-indigenous-forest-privacy.json\"\n",
    "PICO_FILE = \"../inputs/urban-imagery-privacy/pico-urban-imagery-privacy.json\"\n",
    "PICO_FILE = \"../inputs/wildfire-sentinel2-ml/pico-wildfire-sentinel2-ml.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ‚öôÔ∏è SECTION 2: SETUP\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (uncomment if needed)\n",
    "# !pip install nanopub rdflib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Setup complete\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from rdflib import Graph, Dataset, Namespace, Literal, URIRef\n",
    "from rdflib.namespace import RDF, RDFS, XSD, FOAF\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "# Namespaces (matching Nanodash)\n",
    "NP = Namespace(\"http://www.nanopub.org/nschema#\")\n",
    "DCT = Namespace(\"http://purl.org/dc/terms/\")\n",
    "NT = Namespace(\"https://w3id.org/np/o/ntemplate/\")\n",
    "NPX = Namespace(\"http://purl.org/nanopub/x/\")\n",
    "PROV = Namespace(\"http://www.w3.org/ns/prov#\")\n",
    "ORCID = Namespace(\"https://orcid.org/\")\n",
    "\n",
    "# Cochrane PICO ontology\n",
    "PICO = Namespace(\"http://data.cochrane.org/ontologies/pico/\")\n",
    "\n",
    "# Science Live ontology for question types\n",
    "SCIENCELIVE = Namespace(\"https://w3id.org/sciencelive/o/terms/\")\n",
    "\n",
    "# PICO template URIs (NEW TEMPLATE)\n",
    "PICO_TEMPLATE = URIRef(\"https://w3id.org/np/RA5e5XeXy_-aNK5giB7kBAEQslTLVydHeM4YYEzhmEE2w\")\n",
    "PICO_TEMPLATE_NS = Namespace(\"https://w3id.org/np/RA5e5XeXy_-aNK5giB7kBAEQslTLVydHeM4YYEzhmEE2w/\")\n",
    "\n",
    "# Template references\n",
    "PROV_TEMPLATE = URIRef(\"https://w3id.org/np/RA7lSq6MuK_TIC6JMSHvLtee3lpLoZDOqLJCLXevnrPoU\")\n",
    "PUBINFO_TEMPLATE_1 = URIRef(\"https://w3id.org/np/RA0J4vUn_dekg-U1kK3AOEt02p9mT2WO03uGxLDec1jLw\")\n",
    "PUBINFO_TEMPLATE_2 = URIRef(\"https://w3id.org/np/RAukAcWHRDlkqxk7H2XNSegc1WnHI569INvNr-xdptDGI\")\n",
    "PUBINFO_TEMPLATE_3 = URIRef(\"https://w3id.org/np/RAoTD7udB2KtUuOuAe74tJi1t3VzK0DyWS7rYVAq1GRvw\")\n",
    "\n",
    "# Question type mapping (new Science Live URIs)\n",
    "QUESTION_TYPE_MAP = {\n",
    "    \"causation\": SCIENCELIVE.CausationResearchQuestion,\n",
    "    \"descriptive\": SCIENCELIVE.DescriptiveResearchQuestion,\n",
    "    \"effectiveness\": SCIENCELIVE.EffectivenessResearchQuestions,\n",
    "    \"experience\": SCIENCELIVE.ExperienceResearchQuestions,\n",
    "    \"prediction\": SCIENCELIVE.PredictionResearchQuestions,\n",
    "}\n",
    "\n",
    "VALID_QUESTION_TYPES = list(QUESTION_TYPE_MAP.keys())\n",
    "\n",
    "print(\"‚úì Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìñ SECTION 3: LOAD & VALIDATE\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ../inputs/wildfire-sentinel2-ml/pico-wildfire-sentinel2-ml.json\n",
      "‚úì Loaded PICO: Machine Learning Algorithms for Wildfire Detection...\n"
     ]
    }
   ],
   "source": [
    "# Load PICO from JSON\n",
    "print(f\"Loading: {PICO_FILE}\")\n",
    "\n",
    "with open(PICO_FILE, 'r', encoding='utf-8') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Extract fields\n",
    "AUTHOR_ORCID = config['author']['orcid']\n",
    "AUTHOR_NAME = config['author']['name']\n",
    "\n",
    "TITLE = config['pico']['title']\n",
    "POPULATION = config['pico']['population']\n",
    "INTERVENTION = config['pico']['intervention']\n",
    "COMPARISON = config['pico']['comparison']\n",
    "OUTCOME = config['pico']['outcome']\n",
    "RESEARCH_QUESTION = config['pico']['research_question']\n",
    "QUESTION_TYPE = config['pico']['question_type']\n",
    "RATIONALE = config['pico'].get('rationale', '')  # Optional (not used in new template)\n",
    "\n",
    "OUTPUT_FILENAME = config['output']['filename']\n",
    "\n",
    "print(f\"‚úì Loaded PICO: {TITLE[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "‚úì All fields valid\n"
     ]
    }
   ],
   "source": [
    "# Validate\n",
    "print(\"Validating...\")\n",
    "\n",
    "errors = []\n",
    "if not AUTHOR_ORCID:\n",
    "    errors.append(\"author.orcid is required\")\n",
    "if not AUTHOR_NAME:\n",
    "    errors.append(\"author.name is required\")\n",
    "if not TITLE or len(TITLE) < 10:\n",
    "    errors.append(\"pico.title must be at least 10 characters\")\n",
    "if not POPULATION:\n",
    "    errors.append(\"pico.population is required\")\n",
    "if not INTERVENTION:\n",
    "    errors.append(\"pico.intervention is required\")\n",
    "if not OUTCOME:\n",
    "    errors.append(\"pico.outcome is required\")\n",
    "if not RESEARCH_QUESTION:\n",
    "    errors.append(\"pico.research_question is required\")\n",
    "if QUESTION_TYPE not in VALID_QUESTION_TYPES:\n",
    "    errors.append(f\"pico.question_type must be one of: {VALID_QUESTION_TYPES}\")\n",
    "\n",
    "if errors:\n",
    "    print(\"‚ùå Validation errors:\")\n",
    "    for e in errors:\n",
    "        print(f\"   - {e}\")\n",
    "    raise ValueError(\"Please fix the errors in your JSON file\")\n",
    "else:\n",
    "    print(\"‚úì All fields valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Generated PICO ID: machine-learning-algorithms-for-wildfire-detection\n"
     ]
    }
   ],
   "source": [
    "# Generate a URI-safe ID from the title for the PICO resource\n",
    "def slugify(text, max_length=50):\n",
    "    \"\"\"Create a URL-safe slug from text.\"\"\"\n",
    "    # Convert to lowercase and replace spaces with hyphens\n",
    "    slug = text.lower().strip()\n",
    "    slug = re.sub(r'[^a-z0-9\\s-]', '', slug)  # Remove special chars\n",
    "    slug = re.sub(r'[\\s_]+', '-', slug)  # Replace spaces/underscores with hyphens\n",
    "    slug = re.sub(r'-+', '-', slug)  # Remove consecutive hyphens\n",
    "    slug = slug.strip('-')  # Remove leading/trailing hyphens\n",
    "    return slug[:max_length]\n",
    "\n",
    "PICO_ID = slugify(TITLE)\n",
    "print(f\"‚úì Generated PICO ID: {PICO_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üî® SECTION 4: BUILD NANOPUBLICATION\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Dataset created\n"
     ]
    }
   ],
   "source": [
    "# Create dataset with named graphs\n",
    "TEMP_NP = Namespace(\"http://purl.org/nanopub/temp/np/\")\n",
    "\n",
    "this_np = URIRef(\"http://purl.org/nanopub/temp/np/\")\n",
    "head_graph = URIRef(\"http://purl.org/nanopub/temp/np/Head\")\n",
    "assertion_graph = URIRef(\"http://purl.org/nanopub/temp/np/assertion\")\n",
    "provenance_graph = URIRef(\"http://purl.org/nanopub/temp/np/provenance\")\n",
    "pubinfo_graph = URIRef(\"http://purl.org/nanopub/temp/np/pubinfo\")\n",
    "\n",
    "ds = Dataset()\n",
    "\n",
    "# Bind prefixes\n",
    "ds.bind(\"this\", \"http://purl.org/nanopub/temp/np/\")\n",
    "ds.bind(\"sub\", TEMP_NP)\n",
    "ds.bind(\"np\", NP)\n",
    "ds.bind(\"dct\", DCT)\n",
    "ds.bind(\"nt\", NT)\n",
    "ds.bind(\"npx\", NPX)\n",
    "ds.bind(\"xsd\", XSD)\n",
    "ds.bind(\"rdfs\", RDFS)\n",
    "ds.bind(\"orcid\", ORCID)\n",
    "ds.bind(\"prov\", PROV)\n",
    "ds.bind(\"foaf\", FOAF)\n",
    "ds.bind(\"pico\", PICO)\n",
    "ds.bind(\"sciencelive\", SCIENCELIVE)\n",
    "\n",
    "print(\"‚úì Dataset created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Head: 4 triples\n"
     ]
    }
   ],
   "source": [
    "# HEAD\n",
    "head = ds.graph(head_graph)\n",
    "head.add((this_np, RDF.type, NP.Nanopublication))\n",
    "head.add((this_np, NP.hasAssertion, assertion_graph))\n",
    "head.add((this_np, NP.hasProvenance, provenance_graph))\n",
    "head.add((this_np, NP.hasPublicationInfo, pubinfo_graph))\n",
    "print(f\"‚úì Head: {len(head)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Assertion: 12 triples\n"
     ]
    }
   ],
   "source": [
    "# ASSERTION - Using Cochrane PICO ontology structure\n",
    "assertion = ds.graph(assertion_graph)\n",
    "\n",
    "# Create local resource URIs\n",
    "pico_uri = TEMP_NP[PICO_ID]\n",
    "population_uri = TEMP_NP[\"population\"]\n",
    "intervention_uri = TEMP_NP[\"interventionGroup\"]\n",
    "comparator_uri = TEMP_NP[\"comparatorGroup\"]\n",
    "outcome_uri = TEMP_NP[\"outcomeGroup\"]\n",
    "\n",
    "# Main PICO resource\n",
    "assertion.add((pico_uri, RDF.type, PICO.PICO))  # st1: type PICO\n",
    "assertion.add((pico_uri, RDF.type, QUESTION_TYPE_MAP[QUESTION_TYPE]))  # st1b: question type\n",
    "assertion.add((pico_uri, RDFS.label, Literal(TITLE)))  # st2: label\n",
    "assertion.add((pico_uri, DCT.description, Literal(RESEARCH_QUESTION)))  # st3: description\n",
    "\n",
    "# Population (P)\n",
    "assertion.add((pico_uri, PICO.population, population_uri))  # st4a\n",
    "assertion.add((population_uri, DCT.description, Literal(POPULATION)))  # st4b\n",
    "\n",
    "# Intervention (I)\n",
    "assertion.add((pico_uri, PICO.interventionGroup, intervention_uri))  # st5a\n",
    "assertion.add((intervention_uri, DCT.description, Literal(INTERVENTION)))  # st5b\n",
    "\n",
    "# Comparator (C)\n",
    "assertion.add((pico_uri, PICO.comparatorGroup, comparator_uri))  # st6a\n",
    "assertion.add((comparator_uri, DCT.description, Literal(COMPARISON)))  # st6b\n",
    "\n",
    "# Outcome (O)\n",
    "assertion.add((pico_uri, PICO.outcomeGroup, outcome_uri))  # st7a\n",
    "assertion.add((outcome_uri, DCT.description, Literal(OUTCOME)))  # st7b\n",
    "\n",
    "print(f\"‚úì Assertion: {len(assertion)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Provenance: 1 triples\n"
     ]
    }
   ],
   "source": [
    "# PROVENANCE\n",
    "provenance = ds.graph(provenance_graph)\n",
    "author_uri = ORCID[AUTHOR_ORCID]\n",
    "provenance.add((assertion_graph, PROV.wasAttributedTo, author_uri))\n",
    "print(f\"‚úì Provenance: {len(provenance)} triples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Pubinfo: 12 triples\n"
     ]
    }
   ],
   "source": [
    "# PUBINFO\n",
    "pubinfo = ds.graph(pubinfo_graph)\n",
    "now = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")\n",
    "\n",
    "pubinfo.add((author_uri, FOAF.name, Literal(AUTHOR_NAME)))\n",
    "pubinfo.add((this_np, DCT.created, Literal(now, datatype=XSD.dateTime)))\n",
    "pubinfo.add((this_np, DCT.creator, author_uri))\n",
    "pubinfo.add((this_np, DCT.license, URIRef(\"https://creativecommons.org/licenses/by/4.0/\")))\n",
    "pubinfo.add((this_np, NPX.wasCreatedAt, URIRef(\"https://nanodash.knowledgepixels.com/\")))\n",
    "\n",
    "# CRITICAL: npx:introduces enables federated SPARQL queries to find this resource\n",
    "# Without this, queries using SERVICE to join on the resource URI will fail\n",
    "pubinfo.add((this_np, NPX.introduces, pico_uri))\n",
    "\n",
    "# Label (truncate if needed)\n",
    "label = f\"PICO Research Question: {TITLE}\"\n",
    "if len(label) > 100:\n",
    "    label = label[:97] + \"...\"\n",
    "pubinfo.add((this_np, RDFS.label, Literal(label)))\n",
    "\n",
    "# Template references (updated for new template)\n",
    "pubinfo.add((this_np, NT.wasCreatedFromProvenanceTemplate, PROV_TEMPLATE))\n",
    "pubinfo.add((this_np, NT.wasCreatedFromPubinfoTemplate, PUBINFO_TEMPLATE_1))\n",
    "pubinfo.add((this_np, NT.wasCreatedFromPubinfoTemplate, PUBINFO_TEMPLATE_2))\n",
    "pubinfo.add((this_np, NT.wasCreatedFromPubinfoTemplate, PUBINFO_TEMPLATE_3))\n",
    "pubinfo.add((this_np, NT.wasCreatedFromTemplate, PICO_TEMPLATE))\n",
    "\n",
    "print(f\"‚úì Pubinfo: {len(pubinfo)} triples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìÑ SECTION 5: OUTPUT\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Saved to: /Users/annef/Documents/FAIR2Adapt/systematic-review-pipeline/notebooks/wildfire-sentinel2-ml-pico.trig\n"
     ]
    }
   ],
   "source": [
    "# Serialize and save\n",
    "trig_output = ds.serialize(format=\"trig\")\n",
    "\n",
    "output_path = Path(f\"{OUTPUT_FILENAME}.trig\")\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(trig_output)\n",
    "\n",
    "print(f\"‚úì Saved to: {output_path.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "NANOPUBLICATION (TriG format)\n",
      "======================================================================\n",
      "@prefix dct: <http://purl.org/dc/terms/> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix np: <http://www.nanopub.org/nschema#> .\n",
      "@prefix npx: <http://purl.org/nanopub/x/> .\n",
      "@prefix nt: <https://w3id.org/np/o/ntemplate/> .\n",
      "@prefix orcid: <https://orcid.org/> .\n",
      "@prefix pico: <http://data.cochrane.org/ontologies/pico/> .\n",
      "@prefix prov: <http://www.w3.org/ns/prov#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix sciencelive: <https://w3id.org/sciencelive/o/terms/> .\n",
      "@prefix sub: <http://purl.org/nanopub/temp/np/> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "sub:pubinfo {\n",
      "    sub: rdfs:label \"PICO Research Question: Machine Learning Algorithms for Wildfire Detection and Burned Area Mappin...\" ;\n",
      "        dct:created \"2026-01-06T10:11:08+00:00\"^^xsd:dateTime ;\n",
      "        dct:creator orcid:0000-0002-1784-2920 ;\n",
      "        dct:license <https://creativecommons.org/licenses/by/4.0/> ;\n",
      "        npx:introduces sub:machine-learning-algorithms-for-wildfire-detection ;\n",
      "        npx:wasCreatedAt <https://nanodash.knowledgepixels.com/> ;\n",
      "        nt:wasCreatedFromProvenanceTemplate <https://w3id.org/np/RA7lSq6MuK_TIC6JMSHvLtee3lpLoZDOqLJCLXevnrPoU> ;\n",
      "        nt:wasCreatedFromPubinfoTemplate <https://w3id.org/np/RA0J4vUn_dekg-U1kK3AOEt02p9mT2WO03uGxLDec1jLw>,\n",
      "            <https://w3id.org/np/RAoTD7udB2KtUuOuAe74tJi1t3VzK0DyWS7rYVAq1GRvw>,\n",
      "            <https://w3id.org/np/RAukAcWHRDlkqxk7H2XNSegc1WnHI569INvNr-xdptDGI> ;\n",
      "        nt:wasCreatedFromTemplate <https://w3id.org/np/RA5e5XeXy_-aNK5giB7kBAEQslTLVydHeM4YYEzhmEE2w> .\n",
      "\n",
      "    orcid:0000-0002-1784-2920 foaf:name \"Anne Fouilloux\" .\n",
      "}\n",
      "\n",
      "sub:assertion {\n",
      "    sub:comparatorGroup dct:description \"Different ML/DL architectures compared against each other; comparison of input data configurations (spectral bands, indices, temporal features); validation approaches (cross-validation, independent test sets, spatial holdout); and where available, comparison with traditional remote sensing methods (thresholding, spectral indices)\" .\n",
      "\n",
      "    sub:interventionGroup dct:description \"Machine learning and deep learning algorithms applied to Sentinel-2 multispectral imagery for wildfire applications, including convolutional neural networks (CNN, U-Net, ResNet, EfficientNet), random forest, support vector machines, gradient boosting methods, and attention-based architectures. Includes both uni-temporal and bi-temporal approaches, as well as fusion with Sentinel-1 SAR data\" .\n",
      "\n",
      "    sub:machine-learning-algorithms-for-wildfire-detection a pico:PICO,\n",
      "            sciencelive:DescriptiveResearchQuestion ;\n",
      "        rdfs:label \"Machine Learning Algorithms for Wildfire Detection and Burned Area Mapping Using Sentinel-2 Imagery: A Systematic Review\" ;\n",
      "        pico:comparatorGroup sub:comparatorGroup ;\n",
      "        pico:interventionGroup sub:interventionGroup ;\n",
      "        pico:outcomeGroup sub:outcomeGroup ;\n",
      "        pico:population sub:population ;\n",
      "        dct:description \"What machine learning algorithms have been developed and validated for wildfire detection, risk prediction, and burned area mapping using Sentinel-2 imagery, and what are their reported performance metrics, geographic coverage, and application readiness?\" .\n",
      "\n",
      "    sub:outcomeGroup dct:description \"Algorithm performance metrics (accuracy, precision, recall, F1-score, IoU, overall accuracy, kappa coefficient), geographic transferability, computational requirements, input data requirements, code and model availability, and operational readiness for wildfire management applications\" .\n",
      "\n",
      "    sub:population dct:description \"Geographic regions affected by wildfires globally, with focus on areas where Sentinel-2 multispectral imagery has been applied for wildfire-related studies, including Mediterranean Europe, California, Australia, Canada, and other fire-prone ecosystems\" .\n",
      "}\n",
      "\n",
      "sub:Head {\n",
      "    sub: a np:Nanopublication ;\n",
      "        np:hasAssertion sub:assertion ;\n",
      "        np:hasProvenance sub:provenance ;\n",
      "        np:hasPublicationInfo sub:pubinfo .\n",
      "}\n",
      "\n",
      "sub:provenance {\n",
      "    sub:assertion prov:wasAttributedTo orcid:0000-0002-1784-2920 .\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display output\n",
    "print(\"=\" * 70)\n",
    "print(\"NANOPUBLICATION (TriG format)\")\n",
    "print(\"=\" * 70)\n",
    "print(trig_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SUMMARY\n",
      "======================================================================\n",
      "Input:    ../inputs/wildfire-sentinel2-ml/pico-wildfire-sentinel2-ml.json\n",
      "Output:   wildfire-sentinel2-ml-pico.trig\n",
      "Author:   Anne Fouilloux (orcid:0000-0002-1784-2920)\n",
      "Type:     descriptive\n",
      "PICO ID:  machine-learning-algorithms-for-wildfire-detection\n",
      "\n",
      "PICO:\n",
      "  Title: Machine Learning Algorithms for Wildfire Detection and Burne...\n",
      "  P: Geographic regions affected by wildfires globally, with...\n",
      "  I: Machine learning and deep learning algorithms applied t...\n",
      "  C: Different ML/DL architectures compared against each oth...\n",
      "  O: Algorithm performance metrics (accuracy, precision, rec...\n",
      "\n",
      "Template: https://w3id.org/np/RA5e5XeXy_-aNK5giB7kBAEQslTLVydHeM4YYEzhmEE2w\n",
      "\n",
      "Next steps:\n",
      "  Sign:    nanopub sign wildfire-sentinel2-ml-pico.trig\n",
      "  Publish: nanopub publish wildfire-sentinel2-ml-pico.signed.trig\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"=\" * 70)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Input:    {PICO_FILE}\")\n",
    "print(f\"Output:   {output_path}\")\n",
    "print(f\"Author:   {AUTHOR_NAME} (orcid:{AUTHOR_ORCID})\")\n",
    "print(f\"Type:     {QUESTION_TYPE}\")\n",
    "print(f\"PICO ID:  {PICO_ID}\")\n",
    "print()\n",
    "print(\"PICO:\")\n",
    "print(f\"  Title: {TITLE[:60]}...\" if len(TITLE) > 60 else f\"  Title: {TITLE}\")\n",
    "print(f\"  P: {POPULATION[:55]}...\" if len(POPULATION) > 55 else f\"  P: {POPULATION}\")\n",
    "print(f\"  I: {INTERVENTION[:55]}...\" if len(INTERVENTION) > 55 else f\"  I: {INTERVENTION}\")\n",
    "print(f\"  C: {COMPARISON[:55]}...\" if len(COMPARISON) > 55 else f\"  C: {COMPARISON}\")\n",
    "print(f\"  O: {OUTCOME[:55]}...\" if len(OUTCOME) > 55 else f\"  O: {OUTCOME}\")\n",
    "print()\n",
    "print(\"Template: https://w3id.org/np/RA5e5XeXy_-aNK5giB7kBAEQslTLVydHeM4YYEzhmEE2w\")\n",
    "print()\n",
    "print(\"Next steps:\")\n",
    "print(f\"  Sign:    nanopub sign {output_path}\")\n",
    "print(f\"  Publish: nanopub publish {output_path.stem}.signed.trig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üöÄ SECTION 6: SIGN & PUBLISH (OPTIONAL)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUBLISH = True\n",
    "USE_TEST_SERVER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded profile: Anne Fouilloux\n",
      "‚úì Signed\n",
      "‚úì Saved: wildfire-sentinel2-ml-pico.signed.trig\n",
      "‚úì Published: https://w3id.org/np/RAjO8tdVOla9I77PeXF4iY92ULngrpx5_ZSKFkVrCmsW0\n"
     ]
    }
   ],
   "source": [
    "if PUBLISH:\n",
    "    from nanopub import Nanopub, NanopubConf, load_profile\n",
    "    \n",
    "    profile = load_profile()\n",
    "    print(f\"Loaded profile: {profile.name}\")\n",
    "    \n",
    "    conf = NanopubConf(profile=profile, use_test_server=USE_TEST_SERVER)\n",
    "    np_obj = Nanopub(rdf=output_path, conf=conf)\n",
    "    \n",
    "    np_obj.sign()\n",
    "    print(f\"‚úì Signed\")\n",
    "    \n",
    "    signed_path = Path(f\"{OUTPUT_FILENAME}.signed.trig\")\n",
    "    np_obj.store(signed_path)\n",
    "    print(f\"‚úì Saved: {signed_path}\")\n",
    "    \n",
    "    np_obj.publish()\n",
    "    print(f\"‚úì Published: {np_obj.source_uri}\")\n",
    "else:\n",
    "    print(\"Publishing disabled. Set PUBLISH = True to enable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìã JSON TEMPLATE\n",
    "\n",
    "Create a JSON file with this structure:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"author\": {\n",
    "    \"orcid\": \"0000-0000-0000-0000\",\n",
    "    \"name\": \"Your Name\"\n",
    "  },\n",
    "  \"pico\": {\n",
    "    \"title\": \"Your systematic review title\",\n",
    "    \"population\": \"Who or what is being studied\",\n",
    "    \"intervention\": \"What intervention or exposure\",\n",
    "    \"comparison\": \"Comparison group (or 'Not applicable')\",\n",
    "    \"outcome\": \"What outcomes are measured\",\n",
    "    \"research_question\": \"Your full research question\",\n",
    "    \"question_type\": \"descriptive\",\n",
    "    \"rationale\": \"Why this review is needed (optional, not used in this template)\"\n",
    "  },\n",
    "  \"output\": {\n",
    "    \"filename\": \"my-pico\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "\n",
    "**Question types:** `causation`, `descriptive`, `effectiveness`, `experience`, `prediction`\n",
    "\n",
    "**Note:** The `evaluation` type is not available in this template.\n",
    "\n",
    "---\n",
    "\n",
    "## Template Changes\n",
    "\n",
    "This notebook uses the **Cochrane PICO ontology** template:\n",
    "- Template: `https://w3id.org/np/RA5e5XeXy_-aNK5giB7kBAEQslTLVydHeM4YYEzhmEE2w`\n",
    "- Uses `pico:population`, `pico:interventionGroup`, `pico:comparatorGroup`, `pico:outcomeGroup`\n",
    "- Question types from Science Live ontology (`https://w3id.org/sciencelive/o/terms/`)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
