{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Inclusion Nanopublication Generator (ASReview Export)\n",
    "\n",
    "This notebook generates nanopublications from ASReview screening results.\n",
    "\n",
    "**Input:** `study_inclusion.json` generated by `asreview-to-nanopub.ipynb`\n",
    "\n",
    "**Output:** One nanopub per included study (283 files for your review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your JSON configuration file from ASReview export\n",
    "STUDY_INCLUSION_FILE = \"../screening_results/study_inclusion.json\"\n",
    "\n",
    "# Output directory for generated nanopubs\n",
    "OUTPUT_DIR = \"nanopubs_study_inclusion\"\n",
    "\n",
    "# Generate all studies or just test with first N?\n",
    "# Set to None for all, or an integer like 3 for testing\n",
    "LIMIT_STUDIES = None  # e.g., 3 for first 3 only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: Quantum Computing Applications in Biodiversity Research\n",
      "Screener: Anne Fouilloux (0000-0002-1784-2920)\n",
      "Screening date: 2025-12-27\n",
      "Tool: ASReview LAB v2.2\n",
      "\n",
      "Studies: 283 included\n",
      "\n",
      "Provenance chain:\n",
      "  PICO: https://w3id.org/np/RA8B3ptXUOsN7obpkFGtA0FBmsh0OnID53wOsUIpSKTcg\n",
      "  Search Strategy: https://w3id.org/np/RAEK3jctU2x3IKW174OTgmFH9zDygPiaD-vb4zGrD39A4\n",
      "  Search Execution: https://w3id.org/np/RAMPy96eCLCXlGR9VvCVf6rJmpN_DlxxarMGm91_5n-O8\n",
      "\n",
      "Sample studies:\n",
      "  1. Joint Optimization of Radio and Computational Resources for ...\n",
      "  2. Machine learning &amp; artificial intelligence in the quantu...\n",
      "  3. The prospects of quantum computing in computational molecula...\n",
      "  4. Quantum Machine Learning Applications in the Biomedical Doma...\n",
      "  5. Quantum-Inspired Real-Time Optimization for 6G Networks: Opp...\n",
      "  ... and 278 more\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "with open(STUDY_INCLUSION_FILE, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Extract metadata from ASReview export format\n",
    "review_meta = config['review_metadata']\n",
    "provenance = config['provenance']\n",
    "studies = config['studies']\n",
    "\n",
    "print(f\"Review: {review_meta['title']}\")\n",
    "print(f\"Screener: {review_meta['screener_name']} ({review_meta['screener_orcid']})\")\n",
    "print(f\"Screening date: {review_meta['screening_date']}\")\n",
    "print(f\"Tool: {review_meta['screening_tool']}\")\n",
    "print()\n",
    "print(f\"Studies: {len(studies)} included\")\n",
    "print()\n",
    "print(\"Provenance chain:\")\n",
    "print(f\"  PICO: {provenance['pico_nanopub']}\")\n",
    "print(f\"  Search Strategy: {provenance['search_strategy_nanopub']}\")\n",
    "print(f\"  Search Execution: {provenance['search_execution_nanopub']}\")\n",
    "print()\n",
    "print(\"Sample studies:\")\n",
    "for i, study in enumerate(studies[:5]):\n",
    "    label = study['label'][:60] + \"...\" if len(study['label']) > 60 else study['label']\n",
    "    print(f\"  {i+1}. {label}\")\n",
    "if len(studies) > 5:\n",
    "    print(f\"  ... and {len(studies) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Setup Namespaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Namespaces configured\n",
      "✓ Output directory: nanopubs_study_inclusion/\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timezone\n",
    "from rdflib import Graph, Dataset, Namespace, URIRef, Literal\n",
    "from rdflib.namespace import RDF, RDFS, XSD, FOAF, PROV\n",
    "\n",
    "# Define namespaces\n",
    "NP = Namespace(\"http://www.nanopub.org/nschema#\")\n",
    "NPX = Namespace(\"http://purl.org/nanopub/x/\")\n",
    "NT = Namespace(\"https://w3id.org/np/o/ntemplate/\")\n",
    "ORCID = Namespace(\"https://orcid.org/\")\n",
    "SLV = Namespace(\"https://w3id.org/sciencelive/o/terms/\")\n",
    "DISCO = Namespace(\"http://rdf-vocabulary.ddialliance.org/discovery#\")\n",
    "DCT = Namespace(\"http://purl.org/dc/terms/\")\n",
    "TEMP_NP = Namespace(\"http://purl.org/nanopub/temp/np/\")\n",
    "\n",
    "# Template URIs\n",
    "STUDY_INCLUSION_TEMPLATE = URIRef(\"https://w3id.org/np/RAivw_N13pxVoXRMP6Y3ErfA--Z011qMqwKccfiKVxF0w\")\n",
    "PROVENANCE_TEMPLATE = URIRef(\"https://w3id.org/np/RA7lSq6MuK_TIC6JMSHvLtee3lpLoZDOqLJCLXevnrPoU\")\n",
    "PUBINFO_TEMPLATE_1 = URIRef(\"https://w3id.org/np/RA0J4vUn_dekg-U1kK3AOEt02p9mT2WO03uGxLDec1jLw\")\n",
    "PUBINFO_TEMPLATE_2 = URIRef(\"https://w3id.org/np/RAukAcWHRDlkqxk7H2XNSegc1WnHI569INvNr-xdptDGI\")\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "print(\"✓ Namespaces configured\")\n",
    "print(f\"✓ Output directory: {OUTPUT_DIR}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Define Nanopub Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Function defined\n"
     ]
    }
   ],
   "source": [
    "def create_study_inclusion_nanopub(study_data, systematic_review_uri, author_orcid, author_name):\n",
    "    \"\"\"\n",
    "    Create a Study Inclusion nanopub for a single study.\n",
    "    \n",
    "    Args:\n",
    "        study_data: dict with 'label' and 'uri' keys\n",
    "        systematic_review_uri: URI of the systematic review/PICO nanopub\n",
    "        author_orcid: ORCID ID of the screener\n",
    "        author_name: Name of the screener\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (Dataset, trig_string)\n",
    "    \"\"\"\n",
    "    ds = Dataset()\n",
    "    ds.bind(\"this\", \"http://purl.org/nanopub/temp/np/\")\n",
    "    ds.bind(\"sub\", TEMP_NP)\n",
    "    ds.bind(\"np\", NP)\n",
    "    ds.bind(\"dct\", DCT)\n",
    "    ds.bind(\"nt\", NT)\n",
    "    ds.bind(\"npx\", NPX)\n",
    "    ds.bind(\"xsd\", XSD)\n",
    "    ds.bind(\"rdfs\", RDFS)\n",
    "    ds.bind(\"orcid\", ORCID)\n",
    "    ds.bind(\"prov\", PROV)\n",
    "    ds.bind(\"foaf\", FOAF)\n",
    "    ds.bind(\"slv\", SLV)\n",
    "    ds.bind(\"disco\", DISCO)\n",
    "    \n",
    "    # URIs\n",
    "    np_uri = URIRef(\"http://purl.org/nanopub/temp/np/\")\n",
    "    head_uri = TEMP_NP.Head\n",
    "    assertion_uri = TEMP_NP.assertion\n",
    "    provenance_uri = TEMP_NP.provenance\n",
    "    pubinfo_uri = TEMP_NP.pubinfo\n",
    "    study_uri = TEMP_NP.study\n",
    "    author_uri = ORCID[author_orcid]\n",
    "    \n",
    "    # HEAD graph\n",
    "    head = ds.graph(head_uri)\n",
    "    head.add((np_uri, RDF.type, NP.Nanopublication))\n",
    "    head.add((np_uri, NP.hasAssertion, assertion_uri))\n",
    "    head.add((np_uri, NP.hasProvenance, provenance_uri))\n",
    "    head.add((np_uri, NP.hasPublicationInfo, pubinfo_uri))\n",
    "    \n",
    "    # ASSERTION graph\n",
    "    assertion = ds.graph(assertion_uri)\n",
    "    assertion.add((study_uri, RDF.type, DISCO.Study))\n",
    "    assertion.add((study_uri, RDFS.label, Literal(study_data['label'])))\n",
    "    assertion.add((study_uri, DCT.source, URIRef(study_data['uri'])))\n",
    "    assertion.add((URIRef(systematic_review_uri), SLV.includesStudy, study_uri))\n",
    "    \n",
    "    # PROVENANCE graph\n",
    "    provenance = ds.graph(provenance_uri)\n",
    "    provenance.add((assertion_uri, PROV.wasAttributedTo, author_uri))\n",
    "    \n",
    "    # PUBINFO graph\n",
    "    pubinfo = ds.graph(pubinfo_uri)\n",
    "    pubinfo.add((author_uri, FOAF.name, Literal(author_name)))\n",
    "    \n",
    "    timestamp = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%S.%f\")[:-3] + \"Z\"\n",
    "    pubinfo.add((np_uri, DCT.created, Literal(timestamp, datatype=XSD.dateTime)))\n",
    "    pubinfo.add((np_uri, DCT.creator, author_uri))\n",
    "    pubinfo.add((np_uri, DCT.license, URIRef(\"https://creativecommons.org/licenses/by/4.0/\")))\n",
    "    pubinfo.add((np_uri, NPX.introduces, study_uri))\n",
    "    pubinfo.add((np_uri, NPX.wasCreatedAt, URIRef(\"https://nanodash.knowledgepixels.com/\")))\n",
    "    \n",
    "    # Label (truncated)\n",
    "    label = study_data['label'][:50] + \"...\" if len(study_data['label']) > 50 else study_data['label']\n",
    "    pubinfo.add((np_uri, RDFS.label, Literal(label)))\n",
    "    \n",
    "    # Template references\n",
    "    pubinfo.add((np_uri, NT.wasCreatedFromTemplate, STUDY_INCLUSION_TEMPLATE))\n",
    "    pubinfo.add((np_uri, NT.wasCreatedFromProvenanceTemplate, PROVENANCE_TEMPLATE))\n",
    "    pubinfo.add((np_uri, NT.wasCreatedFromPubinfoTemplate, PUBINFO_TEMPLATE_1))\n",
    "    pubinfo.add((np_uri, NT.wasCreatedFromPubinfoTemplate, PUBINFO_TEMPLATE_2))\n",
    "    \n",
    "    return ds, ds.serialize(format='trig')\n",
    "\n",
    "print(\"✓ Function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Generate Nanopubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 283 nanopubs...\n",
      "\n",
      "  Generated 50/283...\n",
      "  Generated 100/283...\n",
      "  Generated 150/283...\n",
      "  Generated 200/283...\n",
      "  Generated 250/283...\n",
      "\n",
      "✅ Generated: 238 nanopub files\n",
      "⚠️  Skipped: 45 studies without DOI/URL\n"
     ]
    }
   ],
   "source": [
    "# Determine which studies to process\n",
    "if LIMIT_STUDIES is not None:\n",
    "    studies_to_process = studies[:LIMIT_STUDIES]\n",
    "else:\n",
    "    studies_to_process = studies\n",
    "\n",
    "print(f\"Generating {len(studies_to_process)} nanopubs...\")\n",
    "print()\n",
    "\n",
    "generated_files = []\n",
    "skipped = 0\n",
    "\n",
    "for idx, study in enumerate(studies_to_process):\n",
    "    # Skip studies without valid URIs\n",
    "    if not study.get('uri') or study['uri'].startswith('urn:study:'):\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    ds, trig_output = create_study_inclusion_nanopub(\n",
    "        study_data=study,\n",
    "        systematic_review_uri=provenance['pico_nanopub'],\n",
    "        author_orcid=review_meta['screener_orcid'],\n",
    "        author_name=review_meta['screener_name']\n",
    "    )\n",
    "    \n",
    "    # Generate filename\n",
    "    filename = f\"{OUTPUT_DIR}/study-inclusion-{idx+1:03d}.trig\"\n",
    "    Path(filename).write_text(trig_output)\n",
    "    generated_files.append(filename)\n",
    "    \n",
    "    # Progress indicator (every 50 files)\n",
    "    if (idx + 1) % 50 == 0:\n",
    "        print(f\"  Generated {idx + 1}/{len(studies_to_process)}...\")\n",
    "\n",
    "print()\n",
    "print(f\"✅ Generated: {len(generated_files)} nanopub files\")\n",
    "if skipped > 0:\n",
    "    print(f\"⚠️  Skipped: {skipped} studies without DOI/URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Display Sample Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample output (nanopubs_study_inclusion/study-inclusion-001.trig):\n",
      "============================================================\n",
      "@prefix dct: <http://purl.org/dc/terms/> .\n",
      "@prefix disco: <http://rdf-vocabulary.ddialliance.org/discovery#> .\n",
      "@prefix foaf: <http://xmlns.com/foaf/0.1/> .\n",
      "@prefix np: <http://www.nanopub.org/nschema#> .\n",
      "@prefix npx: <http://purl.org/nanopub/x/> .\n",
      "@prefix nt: <https://w3id.org/np/o/ntemplate/> .\n",
      "@prefix orcid: <https://orcid.org/> .\n",
      "@prefix prov: <http://www.w3.org/ns/prov#> .\n",
      "@prefix rdfs: <http://www.w3.org/2000/01/rdf-schema#> .\n",
      "@prefix slv: <https://w3id.org/sciencelive/o/terms/> .\n",
      "@prefix sub: <http://purl.org/nanopub/temp/np/> .\n",
      "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
      "\n",
      "sub:assertion {\n",
      "    <https://w3id.org/np/RA8B3ptXUOsN7obpkFGtA0FBmsh0OnID53wOsUIpSKTcg> slv:includesStudy sub:study .\n",
      "\n",
      "    sub:study a disco:Study ;\n",
      "        rdfs:label \"Joint Optimization of Radio and Computational Resources for Multicell Mobile-Edge Computing\" ;\n",
      "        dct:source <https://doi.org/10.1109/tsipn.2015.2448520> .\n",
      "}\n",
      "\n",
      "sub:provenance {\n",
      "    sub:assertion prov:wasAttributedTo orcid:0000-0002-1784-2920 .\n",
      "}\n",
      "\n",
      "sub:Head {\n",
      "    sub: a np:Nanopublication ;\n",
      "        np:hasAssertion sub:assertion ;\n",
      "        np:hasProvenance sub:provenance ;\n",
      "        np:hasPublicationInfo sub:pubinfo .\n",
      "}\n",
      "\n",
      "sub:pubinfo {\n",
      "    sub: rdfs:label \"Joint Optimization of Radio and Computational Reso...\" ;\n",
      "        dct:created \"2025-12-27T16:24:44.069Z\"^^xsd:dateTime ;\n",
      "        dct:creator orcid:0000-0002-1784-2920 ;\n",
      "        dct:license <https://creativecommons.org/licenses/by/4.0/> ;\n",
      "        npx:introduces sub:study ;\n",
      "        npx:wasCreatedAt <https://nanodash.knowledgepixels.com/> ;\n",
      "        nt:wasCreatedFromProvenanceTemplate <https://w3id.org/np/RA7lSq6MuK_TIC6JMSHvLtee3lpLoZDOqLJCLXevnrPoU> ;\n",
      "        nt:wasCreatedFromPubinfoTemplate <https://w3id.org/np/RA0J4vUn_dekg-U1kK3AOEt02p9mT2WO03uGxLDec1jLw>,\n",
      "            <https://w3id.org/np/RAukAcWHRDlkqxk7H2XNSegc1WnHI569INvNr-xdptDGI> ;\n",
      "        nt:wasCreatedFromTemplate <https://w3id.org/np/RAivw_N13pxVoXRMP6Y3ErfA--Z011qMqwKccfiKVxF0w> .\n",
      "\n",
      "    orcid:0000-0002-1784-2920 foaf:name \"Anne Fouilloux\" .\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if generated_files:\n",
    "    sample_file = Path(generated_files[0])\n",
    "    print(f\"Sample output ({sample_file}):\")\n",
    "    print(\"=\" * 60)\n",
    "    print(sample_file.read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Validate Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation passed for nanopubs_study_inclusion/study-inclusion-001.trig\n"
     ]
    }
   ],
   "source": [
    "from nanopub import Nanopub, NanopubConf\n",
    "\n",
    "conf = NanopubConf(use_test_server=True)\n",
    "\n",
    "if generated_files:\n",
    "    try:\n",
    "        np_obj = Nanopub(rdf=Path(generated_files[0]), conf=conf)\n",
    "        print(f\"✅ Validation passed for {generated_files[0]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Validation error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GENERATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Review: Quantum Computing Applications in Biodiversity Research\n",
      "Screener: Anne Fouilloux\n",
      "\n",
      "Results:\n",
      "  Total included studies: 283\n",
      "  Nanopubs generated: 238\n",
      "  Skipped (no DOI): 45\n",
      "\n",
      "Output files in: nanopubs_study_inclusion/\n",
      "\n",
      "Provenance chain:\n",
      "  1. PICO: https://w3id.org/np/RA8B3ptXUOsN7obpkFGtA0FBmsh0OnID53wOsUIpSKTcg\n",
      "  2. Search Strategy: https://w3id.org/np/RAEK3jctU2x3IKW174OTgmFH9zDygPiaD-vb4zGrD39A4\n",
      "  3. Search Execution: https://w3id.org/np/RAMPy96eCLCXlGR9VvCVf6rJmpN_DlxxarMGm91_5n-O8\n",
      "  4. Study Inclusion: 238 nanopubs\n",
      "============================================================\n",
      "\n",
      "Next: Run Step 9 to batch sign and publish (optional)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"GENERATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nReview: {review_meta['title']}\")\n",
    "print(f\"Screener: {review_meta['screener_name']}\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Total included studies: {len(studies)}\")\n",
    "print(f\"  Nanopubs generated: {len(generated_files)}\")\n",
    "print(f\"  Skipped (no DOI): {skipped}\")\n",
    "print(f\"\\nOutput files in: {OUTPUT_DIR}/\")\n",
    "print(f\"\\nProvenance chain:\")\n",
    "print(f\"  1. PICO: {provenance['pico_nanopub']}\")\n",
    "print(f\"  2. Search Strategy: {provenance['search_strategy_nanopub']}\")\n",
    "print(f\"  3. Search Execution: {provenance['search_execution_nanopub']}\")\n",
    "print(f\"  4. Study Inclusion: {len(generated_files)} nanopubs\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nNext: Run Step 9 to batch sign and publish (optional)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Batch Sign and Publish (Optional)\n",
    "\n",
    "⚠️ **Warning:** This will publish all generated nanopubs. Uncomment only when ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded profile: Anne Fouilloux\n",
      "Published 25/238...\n",
      "Published 50/238...\n",
      "Published 75/238...\n",
      "Published 100/238...\n",
      "Published 125/238...\n",
      "Published 150/238...\n",
      "Published 175/238...\n",
      "Published 200/238...\n",
      "Published 225/238...\n",
      "\n",
      "✅ Published: 238\n",
      "\n",
      "✓ Saved URIs to: nanopubs_study_inclusion/published_uris.json\n"
     ]
    }
   ],
   "source": [
    "# Batch Sign and Publish\n",
    "PUBLISH = True  # Set to True when ready\n",
    "USE_TEST_SERVER = False  # Set to True for testing\n",
    "\n",
    "if PUBLISH:\n",
    "    from nanopub import Nanopub, NanopubConf, load_profile\n",
    "    \n",
    "    profile = load_profile()\n",
    "    print(f\"Loaded profile: {profile.name}\")\n",
    "    \n",
    "    conf = NanopubConf(profile=profile, use_test_server=USE_TEST_SERVER)\n",
    "    \n",
    "    published_uris = []\n",
    "    errors = []\n",
    "    \n",
    "    for i, filename in enumerate(generated_files):\n",
    "        try:\n",
    "            np_obj = Nanopub(rdf=Path(filename), conf=conf)\n",
    "            np_obj.sign()\n",
    "            np_obj.publish()\n",
    "            published_uris.append(np_obj.source_uri)\n",
    "            \n",
    "            if (i + 1) % 25 == 0:\n",
    "                print(f\"Published {i + 1}/{len(generated_files)}...\")\n",
    "        except Exception as e:\n",
    "            errors.append((filename, str(e)))\n",
    "    \n",
    "    print(f\"\\n✅ Published: {len(published_uris)}\")\n",
    "    if errors:\n",
    "        print(f\"❌ Errors: {len(errors)}\")\n",
    "        for f, e in errors[:5]:\n",
    "            print(f\"   {f}: {e}\")\n",
    "    \n",
    "    # Save URIs\n",
    "    output = {\n",
    "        \"review\": review_meta['title'],\n",
    "        \"generated_at\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"total_published\": len(published_uris),\n",
    "        \"nanopub_uris\": published_uris\n",
    "    }\n",
    "    with open(f\"{OUTPUT_DIR}/published_uris.json\", 'w') as f:\n",
    "        json.dump(output, f, indent=2)\n",
    "    print(f\"\\n✓ Saved URIs to: {OUTPUT_DIR}/published_uris.json\")\n",
    "else:\n",
    "    print(\"Publishing disabled. Set PUBLISH = True when ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
