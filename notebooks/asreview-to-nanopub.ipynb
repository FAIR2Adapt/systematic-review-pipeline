{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASReview Results to Nanopublication Export\n",
    "\n",
    "This notebook extracts screening results from an ASReview `.asreview` project file and generates:\n",
    "1. **study_inclusion.json** - Ready for nanopub generation\n",
    "2. **PRISMA flow diagram data**\n",
    "3. **Export files** (CSV, RIS) for included/excluded studies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "\n",
    "Edit these settings for your review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === EDIT THIS SECTION ===\n",
    "\n",
    "# Path to your exported .asreview file\n",
    "ASREVIEW_FILE = \"search_results_combined.asreview\"\n",
    "\n",
    "# Review metadata\n",
    "REVIEW_TITLE = \"Quantum Computing Applications in Biodiversity Research\"\n",
    "REVIEW_DESCRIPTION = \"Systematic review of quantum computing methods applied to biodiversity, conservation, and ecological research\"\n",
    "\n",
    "# Screener info (for provenance)\n",
    "SCREENER_ORCID = \"0000-0002-1784-2920\"\n",
    "SCREENER_NAME = \"Anne Fouilloux\"\n",
    "\n",
    "# Link to your systematic review nanopubs (provenance chain)\n",
    "PICO_NANOPUB_URI = \"https://w3id.org/np/RA8B3ptXUOsN7obpkFGtA0FBmsh0OnID53wOsUIpSKTcg\"\n",
    "SEARCH_STRATEGY_URI = \"https://w3id.org/np/RAEK3jctU2x3IKW174OTgmFH9zDygPiaD-vb4zGrD39A4\"\n",
    "SEARCH_EXECUTION_URI = \"https://w3id.org/np/RAMPy96eCLCXlGR9VvCVf6rJmpN_DlxxarMGm91_5n-O8\"\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"screening_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your exported .asreview file\n",
    "ASREVIEW_FILE = \"wildfire-sentinel2-ml/results/wildfire-sentinel2-ml-no-duplicates.asreview\"\n",
    "\n",
    "# Review metadata\n",
    "REVIEW_TITLE = \"Machine Learning Algorithms for Wildfire Detection and Burned Area Mapping using Sentinel-2\"\n",
    "REVIEW_DESCRIPTION = \"Systematic review on Machine Learning Algorithms for Wildfire Detection and Burned Area Mapping using Sentinel-2\"\n",
    "\n",
    "# Screener info (for provenance)\n",
    "SCREENER_ORCID = \"0000-0002-1784-2920\"\n",
    "SCREENER_NAME = \"Anne Fouilloux\"\n",
    "\n",
    "# Link to your systematic review nanopubs (provenance chain)\n",
    "PICO_NANOPUB_URI = \"https://w3id.org/np/RAjO8tdVOla9I77PeXF4iY92ULngrpx5_ZSKFkVrCmsW0\"\n",
    "SEARCH_STRATEGY_URI = \" \"\n",
    "SEARCH_EXECUTION_URI = \" \"\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"wildfire-sentinel2-ml/screening_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your exported .asreview file\n",
    "ASREVIEW_FILE = \"pets-biodiversity/pets-biodiversity.asreview\"\n",
    "\n",
    "# Review metadata\n",
    "REVIEW_TITLE = \"Privacy-Enhancing Technologies for Geospatial Biodiversity Data Sharing: A Scoping Review\"\n",
    "REVIEW_DESCRIPTION = \"In geospatial species occurrence datasets, how do different privacy-enhancing technologies compare to each other and to unprotected sharing in terms of privacy guarantee strength, preservation of ecological analytical utility, and implementation feasibility for biodiversity monitoring organizations?\"\n",
    "\n",
    "# Screener info (for provenance)\n",
    "SCREENER_ORCID = \"0000-0002-1784-2920\"\n",
    "SCREENER_NAME = \"Anne Fouilloux\"\n",
    "\n",
    "# Link to your systematic review nanopubs (provenance chain)\n",
    "PICO_NANOPUB_URI = \"https://w3id.org/np/RAqmVeNbWgL7sNtsr9GqdX0ZTa6aQf3itQmort-JMy4tM\"\n",
    "SEARCH_STRATEGY_URI = \" \"\n",
    "SEARCH_EXECUTION_URI = \" \"\n",
    "\n",
    "# Output directory\n",
    "OUTPUT_DIR = \"pets-biodiversity/screening_results\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Setup complete\n",
      "  ASReview file: pets-biodiversity/pets-biodiversity.asreview\n",
      "  Output directory: pets-biodiversity/screening_results\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "# Create output directory\n",
    "Path(OUTPUT_DIR).mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"✓ Setup complete\")\n",
    "print(f\"  ASReview file: {ASREVIEW_FILE}\")\n",
    "print(f\"  Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Data from ASReview Project\n",
    "\n",
    "The `.asreview` file is a ZIP archive containing:\n",
    "- `project.json` - Project metadata\n",
    "- `data_store.db` - SQLite database with paper metadata\n",
    "- `reviews/*/results.db` - SQLite database with screening decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting to: /var/folders/zf/53jxd5nj2j3dmfjqpx41p24c0000gn/T/tmpt206087t\n",
      "\n",
      "Project contents:\n",
      "  project.json\n",
      "  data_store.db\n",
      "  feature_matrices/tfidf_feature_matrix.npz\n",
      "  data/pets-biodiversity.ris\n",
      "  reviews/a4629b2eb0994c9c8e9f2cd491ffe783/results.db\n",
      "  reviews/a4629b2eb0994c9c8e9f2cd491ffe783/settings_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Extract the .asreview file (it's a ZIP)\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "print(f\"Extracting to: {temp_dir}\")\n",
    "\n",
    "with zipfile.ZipFile(ASREVIEW_FILE, 'r') as zip_ref:\n",
    "    zip_ref.extractall(temp_dir)\n",
    "\n",
    "# List contents\n",
    "print(\"\\nProject contents:\")\n",
    "for item in Path(temp_dir).rglob(\"*\"):\n",
    "    if item.is_file():\n",
    "        print(f\"  {item.relative_to(temp_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project info:\n",
      "  Name: pets-biodiversity\n",
      "  ID: a714685d479740be993013071ab9c8a9\n",
      "  Version: 2.2\n",
      "  Reviews: 1\n"
     ]
    }
   ],
   "source": [
    "# Load project config\n",
    "with open(Path(temp_dir) / \"project.json\") as f:\n",
    "    project_config = json.load(f)\n",
    "\n",
    "print(\"Project info:\")\n",
    "print(f\"  Name: {project_config.get('name', 'N/A')}\")\n",
    "print(f\"  ID: {project_config.get('id', 'N/A')}\")\n",
    "print(f\"  Version: {project_config.get('version', 'N/A')}\")\n",
    "print(f\"  Reviews: {len(project_config.get('reviews', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 21 papers from data store\n",
      "Columns: ['dataset_row', 'dataset_id', 'duplicate_of', 'title', 'abstract', 'authors', 'keywords', 'year', 'doi', 'url', 'included', 'record_id']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_row</th>\n",
       "      <th>dataset_id</th>\n",
       "      <th>duplicate_of</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>authors</th>\n",
       "      <th>keywords</th>\n",
       "      <th>year</th>\n",
       "      <th>doi</th>\n",
       "      <th>url</th>\n",
       "      <th>included</th>\n",
       "      <th>record_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>200622752dcb4da5b948d18545a0ee7b</td>\n",
       "      <td>None</td>\n",
       "      <td>Ethics of Environmental and Biodiversity Data....</td>\n",
       "      <td></td>\n",
       "      <td>[\"Silva-Morales, Milena-Jael\", \"Navarrete, Yas...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.5281/zenodo.17538314</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>200622752dcb4da5b948d18545a0ee7b</td>\n",
       "      <td>None</td>\n",
       "      <td>An Efficient Approach Based on Privacy-Preserv...</td>\n",
       "      <td></td>\n",
       "      <td>[\"Munirah Alkhelaiwi\", \"Wadii Boulila\", \"Jawad...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2021</td>\n",
       "      <td>10.3390/rs13112221</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>200622752dcb4da5b948d18545a0ee7b</td>\n",
       "      <td>None</td>\n",
       "      <td>LUCAS cover photos 2006–2018 over the EU: 874 ...</td>\n",
       "      <td></td>\n",
       "      <td>[\"Rapha\\u00ebl d\\u2019Andrimont\", \"Momchil Yor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2022</td>\n",
       "      <td>10.5194/essd-14-4463-2022</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>200622752dcb4da5b948d18545a0ee7b</td>\n",
       "      <td>None</td>\n",
       "      <td>Ethics of Environmental and Biodiversity Data....</td>\n",
       "      <td></td>\n",
       "      <td>[\"Silva-Morales, Milena-Jael\", \"Navarrete, Yas...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.5281/zenodo.17793473</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>200622752dcb4da5b948d18545a0ee7b</td>\n",
       "      <td>None</td>\n",
       "      <td>Ethics of Environmental and Biodiversity Data....</td>\n",
       "      <td></td>\n",
       "      <td>[\"Milena-Jael Silva-Morales\", \"Yasm\\u00edn Nav...</td>\n",
       "      <td>[]</td>\n",
       "      <td>2025</td>\n",
       "      <td>10.5281/zenodo.17538313</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_row                        dataset_id duplicate_of  \\\n",
       "0            0  200622752dcb4da5b948d18545a0ee7b         None   \n",
       "1            1  200622752dcb4da5b948d18545a0ee7b         None   \n",
       "2            2  200622752dcb4da5b948d18545a0ee7b         None   \n",
       "3            3  200622752dcb4da5b948d18545a0ee7b         None   \n",
       "4            4  200622752dcb4da5b948d18545a0ee7b         None   \n",
       "\n",
       "                                               title abstract  \\\n",
       "0  Ethics of Environmental and Biodiversity Data....            \n",
       "1  An Efficient Approach Based on Privacy-Preserv...            \n",
       "2  LUCAS cover photos 2006–2018 over the EU: 874 ...            \n",
       "3  Ethics of Environmental and Biodiversity Data....            \n",
       "4  Ethics of Environmental and Biodiversity Data....            \n",
       "\n",
       "                                             authors keywords  year  \\\n",
       "0  [\"Silva-Morales, Milena-Jael\", \"Navarrete, Yas...       []  2025   \n",
       "1  [\"Munirah Alkhelaiwi\", \"Wadii Boulila\", \"Jawad...       []  2021   \n",
       "2  [\"Rapha\\u00ebl d\\u2019Andrimont\", \"Momchil Yor...       []  2022   \n",
       "3  [\"Silva-Morales, Milena-Jael\", \"Navarrete, Yas...       []  2025   \n",
       "4  [\"Milena-Jael Silva-Morales\", \"Yasm\\u00edn Nav...       []  2025   \n",
       "\n",
       "                         doi   url included  record_id  \n",
       "0    10.5281/zenodo.17538314  None     None          0  \n",
       "1         10.3390/rs13112221  None     None          1  \n",
       "2  10.5194/essd-14-4463-2022  None     None          2  \n",
       "3    10.5281/zenodo.17793473  None     None          3  \n",
       "4    10.5281/zenodo.17538313  None     None          4  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load paper metadata from data_store.db\n",
    "data_store_path = Path(temp_dir) / \"data_store.db\"\n",
    "\n",
    "conn = sqlite3.connect(data_store_path)\n",
    "papers_df = pd.read_sql_query(\"SELECT * FROM record\", conn)\n",
    "conn.close()\n",
    "\n",
    "print(f\"\\nLoaded {len(papers_df)} papers from data store\")\n",
    "print(f\"Columns: {list(papers_df.columns)}\")\n",
    "papers_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found results database: reviews/a4629b2eb0994c9c8e9f2cd491ffe783/results.db\n",
      "\n",
      "Tables in results.db: ['results', 'decision_changes', 'last_ranking']\n",
      "\n",
      "Screening results: 21 decisions\n",
      "Columns: ['record_id', 'label', 'classifier', 'querier', 'balancer', 'feature_extractor', 'training_set', 'time', 'note', 'tags', 'user_id']\n"
     ]
    }
   ],
   "source": [
    "# Find and load screening results\n",
    "reviews_dir = Path(temp_dir) / \"reviews\"\n",
    "results_db = None\n",
    "\n",
    "for review_dir in reviews_dir.iterdir():\n",
    "    if review_dir.is_dir():\n",
    "        results_path = review_dir / \"results.db\"\n",
    "        if results_path.exists():\n",
    "            results_db = results_path\n",
    "            print(f\"Found results database: {results_path.relative_to(temp_dir)}\")\n",
    "            break\n",
    "\n",
    "if results_db:\n",
    "    conn = sqlite3.connect(results_db)\n",
    "    \n",
    "    # Check available tables\n",
    "    tables = pd.read_sql_query(\"SELECT name FROM sqlite_master WHERE type='table'\", conn)\n",
    "    print(f\"\\nTables in results.db: {list(tables['name'])}\")\n",
    "    \n",
    "    # Load results\n",
    "    results_df = pd.read_sql_query(\"SELECT * FROM results\", conn)\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"\\nScreening results: {len(results_df)} decisions\")\n",
    "    print(f\"Columns: {list(results_df.columns)}\")\n",
    "else:\n",
    "    print(\"ERROR: Could not find results.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in results_df: ['record_id', 'label', 'classifier', 'querier', 'balancer', 'feature_extractor', 'training_set', 'time', 'note', 'tags', 'user_id']\n",
      "\n",
      "Screening summary:\n",
      "status\n",
      "excluded    14\n",
      "included     7\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Merge papers with screening decisions\n",
    "# Check what columns are in results_df\n",
    "print(\"Columns in results_df:\", list(results_df.columns))\n",
    "\n",
    "# Add record_id to papers_df if not present\n",
    "if 'record_id' not in papers_df.columns:\n",
    "    papers_df['record_id'] = papers_df.index\n",
    "\n",
    "# Select only columns that exist in results_df\n",
    "merge_cols = ['record_id', 'label']\n",
    "if 'notes' in results_df.columns:\n",
    "    merge_cols.append('notes')\n",
    "\n",
    "# Merge\n",
    "merged_df = papers_df.merge(\n",
    "    results_df[merge_cols], \n",
    "    on='record_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Categorize\n",
    "merged_df['status'] = merged_df['label'].map({\n",
    "    1: 'included',\n",
    "    0: 'excluded'\n",
    "}).fillna('not_screened')\n",
    "\n",
    "print(\"\\nScreening summary:\")\n",
    "print(merged_df['status'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. PRISMA Flow Diagram Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PRISMA FLOW DIAGRAM DATA\n",
      "============================================================\n",
      "\n",
      "IDENTIFICATION\n",
      "  Total records from databases: 21\n",
      "\n",
      "SCREENING (Title/Abstract)\n",
      "  Records screened: 21\n",
      "  Records excluded: 14\n",
      "  Not screened (AI stopped): 0\n",
      "\n",
      "INCLUDED\n",
      "  Studies after title/abstract screening: 7\n",
      "============================================================\n",
      "\n",
      "✓ Saved: pets-biodiversity/screening_results/prisma_flow_data.json\n"
     ]
    }
   ],
   "source": [
    "# Calculate PRISMA numbers\n",
    "total_records = len(merged_df)\n",
    "screened = len(merged_df[merged_df['status'] != 'not_screened'])\n",
    "included = len(merged_df[merged_df['status'] == 'included'])\n",
    "excluded = len(merged_df[merged_df['status'] == 'excluded'])\n",
    "not_screened = len(merged_df[merged_df['status'] == 'not_screened'])\n",
    "\n",
    "prisma_data = {\n",
    "    \"identification\": {\n",
    "        \"total_records\": total_records,\n",
    "        \"source\": \"Multiple databases (OpenAlex, arXiv, PubMed, Europe PMC, Semantic Scholar)\"\n",
    "    },\n",
    "    \"screening\": {\n",
    "        \"records_screened\": screened,\n",
    "        \"records_excluded_titleabstract\": excluded,\n",
    "        \"not_screened_ai_prioritization\": not_screened,\n",
    "        \"screening_method\": \"ASReview LAB v2.2 (active learning)\"\n",
    "    },\n",
    "    \"included\": {\n",
    "        \"studies_included_titleabstract\": included\n",
    "    },\n",
    "    \"notes\": {\n",
    "        \"ai_assisted\": True,\n",
    "        \"stopping_rule\": \"Consecutive irrelevant threshold\",\n",
    "        \"estimated_recall\": \">95%\"\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PRISMA FLOW DIAGRAM DATA\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nIDENTIFICATION\")\n",
    "print(f\"  Total records from databases: {total_records}\")\n",
    "print(f\"\\nSCREENING (Title/Abstract)\")\n",
    "print(f\"  Records screened: {screened}\")\n",
    "print(f\"  Records excluded: {excluded}\")\n",
    "print(f\"  Not screened (AI stopped): {not_screened}\")\n",
    "print(f\"\\nINCLUDED\")\n",
    "print(f\"  Studies after title/abstract screening: {included}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Save PRISMA data\n",
    "with open(f\"{OUTPUT_DIR}/prisma_flow_data.json\", 'w') as f:\n",
    "    json.dump(prisma_data, f, indent=2)\n",
    "print(f\"\\n✓ Saved: {OUTPUT_DIR}/prisma_flow_data.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Generate Study Inclusion JSON for Nanopubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing 7 included studies for nanopub export\n",
      "\n",
      "Sample of included papers:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>authors</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ethics of Environmental and Biodiversity Data....</td>\n",
       "      <td>10.5281/zenodo.17538314</td>\n",
       "      <td>[\"Silva-Morales, Milena-Jael\", \"Navarrete, Yas...</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>An Efficient Approach Based on Privacy-Preserv...</td>\n",
       "      <td>10.3390/rs13112221</td>\n",
       "      <td>[\"Munirah Alkhelaiwi\", \"Wadii Boulila\", \"Jawad...</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ethics of Environmental and Biodiversity Data....</td>\n",
       "      <td>10.5281/zenodo.17793473</td>\n",
       "      <td>[\"Silva-Morales, Milena-Jael\", \"Navarrete, Yas...</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ethics of Environmental and Biodiversity Data....</td>\n",
       "      <td>10.5281/zenodo.17538313</td>\n",
       "      <td>[\"Milena-Jael Silva-Morales\", \"Yasm\\u00edn Nav...</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Exploring the Methods and the Need for Data An...</td>\n",
       "      <td>10.47611/jsrhs.v13i3.6930</td>\n",
       "      <td>[\"Jason Huang\", \"Linlin Li\", \"Kay H. Chin\", \"K...</td>\n",
       "      <td>2024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Ethics of Environmental and Biodiversity Data....   \n",
       "1  An Efficient Approach Based on Privacy-Preserv...   \n",
       "3  Ethics of Environmental and Biodiversity Data....   \n",
       "4  Ethics of Environmental and Biodiversity Data....   \n",
       "5  Exploring the Methods and the Need for Data An...   \n",
       "\n",
       "                         doi  \\\n",
       "0    10.5281/zenodo.17538314   \n",
       "1         10.3390/rs13112221   \n",
       "3    10.5281/zenodo.17793473   \n",
       "4    10.5281/zenodo.17538313   \n",
       "5  10.47611/jsrhs.v13i3.6930   \n",
       "\n",
       "                                             authors  year  \n",
       "0  [\"Silva-Morales, Milena-Jael\", \"Navarrete, Yas...  2025  \n",
       "1  [\"Munirah Alkhelaiwi\", \"Wadii Boulila\", \"Jawad...  2021  \n",
       "3  [\"Silva-Morales, Milena-Jael\", \"Navarrete, Yas...  2025  \n",
       "4  [\"Milena-Jael Silva-Morales\", \"Yasm\\u00edn Nav...  2025  \n",
       "5  [\"Jason Huang\", \"Linlin Li\", \"Kay H. Chin\", \"K...  2024  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get included studies\n",
    "included_df = merged_df[merged_df['status'] == 'included'].copy()\n",
    "\n",
    "print(f\"Preparing {len(included_df)} included studies for nanopub export\")\n",
    "print(f\"\\nSample of included papers:\")\n",
    "display_cols = ['title', 'doi', 'authors', 'year']\n",
    "available_cols = [c for c in display_cols if c in included_df.columns]\n",
    "included_df[available_cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed 7 studies\n"
     ]
    }
   ],
   "source": [
    "# Build study inclusion JSON\n",
    "def get_study_uri(row):\n",
    "    \"\"\"Get best available URI for the study\"\"\"\n",
    "    if pd.notna(row.get('doi')) and row['doi']:\n",
    "        doi = row['doi']\n",
    "        if not doi.startswith('http'):\n",
    "            return f\"https://doi.org/{doi}\"\n",
    "        return doi\n",
    "    if pd.notna(row.get('url')) and row['url']:\n",
    "        return row['url']\n",
    "    if pd.notna(row.get('openalex_id')) and row['openalex_id']:\n",
    "        return row['openalex_id']\n",
    "    return None\n",
    "\n",
    "def clean_title(title):\n",
    "    \"\"\"Clean title for use as label\"\"\"\n",
    "    if pd.isna(title):\n",
    "        return \"Untitled\"\n",
    "    # Truncate long titles\n",
    "    title = str(title).strip()\n",
    "    if len(title) > 200:\n",
    "        return title[:197] + \"...\"\n",
    "    return title\n",
    "\n",
    "# Build studies list\n",
    "studies = []\n",
    "missing_uri = 0\n",
    "\n",
    "for idx, row in included_df.iterrows():\n",
    "    uri = get_study_uri(row)\n",
    "    if uri is None:\n",
    "        missing_uri += 1\n",
    "        # Use a placeholder URI based on title hash\n",
    "        title_hash = hash(str(row.get('title', idx))) % 10000000\n",
    "        uri = f\"urn:study:{title_hash}\"\n",
    "    \n",
    "    study = {\n",
    "        \"uri\": uri,\n",
    "        \"label\": clean_title(row.get('title')),\n",
    "        \"metadata\": {\n",
    "            \"authors\": row.get('authors', ''),\n",
    "            \"year\": int(row['year']) if pd.notna(row.get('year')) else None,\n",
    "            \"journal\": row.get('journal', row.get('primary_location', '')),\n",
    "            \"doi\": row.get('doi', ''),\n",
    "            \"abstract\": row.get('abstract', '')[:500] if pd.notna(row.get('abstract')) else ''\n",
    "        }\n",
    "    }\n",
    "    studies.append(study)\n",
    "\n",
    "print(f\"\\nProcessed {len(studies)} studies\")\n",
    "if missing_uri > 0:\n",
    "    print(f\"⚠️ {missing_uri} studies without DOI/URL (using placeholder URIs)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: pets-biodiversity/screening_results/study_inclusion.json\n",
      "  Contains 7 studies ready for nanopub generation\n"
     ]
    }
   ],
   "source": [
    "# Create the full study_inclusion.json\n",
    "study_inclusion_config = {\n",
    "    \"_comment\": \"Study Inclusion nanopub configuration for Science Live\",\n",
    "    \"_generated\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"_source\": ASREVIEW_FILE,\n",
    "    \n",
    "    \"review_metadata\": {\n",
    "        \"title\": REVIEW_TITLE,\n",
    "        \"description\": REVIEW_DESCRIPTION,\n",
    "        \"screener_orcid\": SCREENER_ORCID,\n",
    "        \"screener_name\": SCREENER_NAME,\n",
    "        \"screening_date\": datetime.now(timezone.utc).strftime(\"%Y-%m-%d\"),\n",
    "        \"screening_tool\": \"ASReview LAB v2.2\",\n",
    "        \"total_screened\": screened,\n",
    "        \"total_included\": included,\n",
    "        \"total_excluded\": excluded\n",
    "    },\n",
    "    \n",
    "    \"provenance\": {\n",
    "        \"pico_nanopub\": PICO_NANOPUB_URI,\n",
    "        \"search_strategy_nanopub\": SEARCH_STRATEGY_URI,\n",
    "        \"search_execution_nanopub\": SEARCH_EXECUTION_URI\n",
    "    },\n",
    "    \n",
    "    \"nanopub_template\": {\n",
    "        \"base_uri\": \"https://w3id.org/sciencelivehub/quantum-biodiversity-review/\",\n",
    "        \"type\": \"https://w3id.org/slo/StudyInclusion\",\n",
    "        \"license\": \"https://creativecommons.org/licenses/by/4.0/\"\n",
    "    },\n",
    "    \n",
    "    \"studies\": studies\n",
    "}\n",
    "\n",
    "# Save\n",
    "output_file = f\"{OUTPUT_DIR}/study_inclusion.json\"\n",
    "with open(output_file, 'w') as f:\n",
    "    json.dump(study_inclusion_config, f, indent=2, default=str)\n",
    "\n",
    "print(f\"✓ Saved: {output_file}\")\n",
    "print(f\"  Contains {len(studies)} studies ready for nanopub generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export CSV and RIS Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: pets-biodiversity/screening_results/included_studies.csv (7 studies)\n",
      "✓ Saved: pets-biodiversity/screening_results/excluded_studies.csv (14 studies)\n"
     ]
    }
   ],
   "source": [
    "# Export included studies to CSV\n",
    "export_cols = ['title', 'authors', 'year', 'doi', 'journal', 'abstract', 'url']\n",
    "available_export_cols = [c for c in export_cols if c in included_df.columns]\n",
    "\n",
    "included_df[available_export_cols].to_csv(\n",
    "    f\"{OUTPUT_DIR}/included_studies.csv\", \n",
    "    index=False\n",
    ")\n",
    "print(f\"✓ Saved: {OUTPUT_DIR}/included_studies.csv ({len(included_df)} studies)\")\n",
    "\n",
    "# Export excluded studies to CSV\n",
    "excluded_df = merged_df[merged_df['status'] == 'excluded'].copy()\n",
    "excluded_df[available_export_cols].to_csv(\n",
    "    f\"{OUTPUT_DIR}/excluded_studies.csv\", \n",
    "    index=False\n",
    ")\n",
    "print(f\"✓ Saved: {OUTPUT_DIR}/excluded_studies.csv ({len(excluded_df)} studies)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: pets-biodiversity/screening_results/included_studies.ris\n",
      "✓ Saved: pets-biodiversity/screening_results/excluded_studies.ris\n"
     ]
    }
   ],
   "source": [
    "# Export to RIS format for reference managers\n",
    "def df_to_ris(df, filename):\n",
    "    \"\"\"Convert DataFrame to RIS format\"\"\"\n",
    "    with open(filename, 'w', encoding='utf-8') as f:\n",
    "        for idx, row in df.iterrows():\n",
    "            f.write(\"TY  - JOUR\\n\")\n",
    "            \n",
    "            if pd.notna(row.get('title')):\n",
    "                f.write(f\"TI  - {row['title']}\\n\")\n",
    "            \n",
    "            if pd.notna(row.get('authors')):\n",
    "                # Split authors if comma-separated\n",
    "                authors = str(row['authors'])\n",
    "                for author in authors.split(';'):\n",
    "                    author = author.strip()\n",
    "                    if author:\n",
    "                        f.write(f\"AU  - {author}\\n\")\n",
    "            \n",
    "            if pd.notna(row.get('year')):\n",
    "                f.write(f\"PY  - {int(row['year'])}\\n\")\n",
    "            \n",
    "            if pd.notna(row.get('journal')):\n",
    "                f.write(f\"JO  - {row['journal']}\\n\")\n",
    "            \n",
    "            if pd.notna(row.get('doi')):\n",
    "                doi = row['doi']\n",
    "                if not doi.startswith('http'):\n",
    "                    doi = f\"https://doi.org/{doi}\"\n",
    "                f.write(f\"DO  - {row['doi']}\\n\")\n",
    "                f.write(f\"UR  - {doi}\\n\")\n",
    "            elif pd.notna(row.get('url')):\n",
    "                f.write(f\"UR  - {row['url']}\\n\")\n",
    "            \n",
    "            if pd.notna(row.get('abstract')):\n",
    "                # Clean abstract for RIS\n",
    "                abstract = str(row['abstract']).replace('\\n', ' ').strip()\n",
    "                f.write(f\"AB  - {abstract}\\n\")\n",
    "            \n",
    "            f.write(\"ER  - \\n\\n\")\n",
    "\n",
    "# Export included\n",
    "df_to_ris(included_df, f\"{OUTPUT_DIR}/included_studies.ris\")\n",
    "print(f\"✓ Saved: {OUTPUT_DIR}/included_studies.ris\")\n",
    "\n",
    "# Export excluded\n",
    "df_to_ris(excluded_df, f\"{OUTPUT_DIR}/excluded_studies.ris\")\n",
    "print(f\"✓ Saved: {OUTPUT_DIR}/excluded_studies.ris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cleanup and Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cleaned up temporary files\n"
     ]
    }
   ],
   "source": [
    "# Cleanup temp directory\n",
    "shutil.rmtree(temp_dir)\n",
    "print(f\"✓ Cleaned up temporary files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXPORT COMPLETE\n",
      "============================================================\n",
      "\n",
      "Review: Privacy-Enhancing Technologies for Geospatial Biodiversity Data Sharing: A Scoping Review\n",
      "Screener: Anne Fouilloux (0000-0002-1784-2920)\n",
      "\n",
      "Results:\n",
      "  Total records: 21\n",
      "  Screened: 21\n",
      "  Included: 7\n",
      "  Excluded: 14\n",
      "\n",
      "Output files in 'pets-biodiversity/screening_results/' :\n",
      "  • study_inclusion.json     - For nanopub generation\n",
      "  • prisma_flow_data.json    - PRISMA diagram numbers\n",
      "  • included_studies.csv     - Included studies\n",
      "  • excluded_studies.csv     - Excluded studies\n",
      "  • included_studies.ris     - For Zotero/reference managers\n",
      "  • excluded_studies.ris     - For Zotero/reference managers\n",
      "\n",
      "Provenance chain:\n",
      "  PICO → Search Strategy → Search Execution → Study Inclusion\n",
      "============================================================\n",
      "\n",
      "Next step: Run study-inclusion-nanopub-from-json.ipynb\n",
      "           with study_inclusion.json to generate nanopubs\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "print(\"=\"*60)\n",
    "print(\"EXPORT COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nReview: {REVIEW_TITLE}\")\n",
    "print(f\"Screener: {SCREENER_NAME} ({SCREENER_ORCID})\")\n",
    "print(f\"\\nResults:\")\n",
    "print(f\"  Total records: {total_records}\")\n",
    "print(f\"  Screened: {screened}\")\n",
    "print(f\"  Included: {included}\")\n",
    "print(f\"  Excluded: {excluded}\")\n",
    "print(f\"\\nOutput files in '{OUTPUT_DIR}/' :\")\n",
    "print(f\"  • study_inclusion.json     - For nanopub generation\")\n",
    "print(f\"  • prisma_flow_data.json    - PRISMA diagram numbers\")\n",
    "print(f\"  • included_studies.csv     - Included studies\")\n",
    "print(f\"  • excluded_studies.csv     - Excluded studies\")\n",
    "print(f\"  • included_studies.ris     - For Zotero/reference managers\")\n",
    "print(f\"  • excluded_studies.ris     - For Zotero/reference managers\")\n",
    "print(f\"\\nProvenance chain:\")\n",
    "print(f\"  PICO → Search Strategy → Search Execution → Study Inclusion\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nNext step: Run study-inclusion-nanopub-from-json.ipynb\")\n",
    "print(\"           with study_inclusion.json to generate nanopubs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Preview Study Inclusion JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of study_inclusion.json:\n",
      "\n",
      "{\n",
      "  \"review_metadata\": {\n",
      "    \"title\": \"Privacy-Enhancing Technologies for Geospatial Biodiversity Data Sharing: A Scoping Review\",\n",
      "    \"description\": \"In geospatial species occurrence datasets, how do different privacy-enhancing technologies compare to each other and to unprotected sharing in terms of privacy guarantee strength, preservation of ecological analytical utility, and implementation feasibility for biodiversity monitoring organizations?\",\n",
      "    \"screener_orcid\": \"0000-0002-1784-2920\",\n",
      "    \"screener_name\": \"Anne Fouilloux\",\n",
      "    \"screening_date\": \"2026-01-10\",\n",
      "    \"screening_tool\": \"ASReview LAB v2.2\",\n",
      "    \"total_screened\": 21,\n",
      "    \"total_included\": 7,\n",
      "    \"total_excluded\": 14\n",
      "  },\n",
      "  \"provenance\": {\n",
      "    \"pico_nanopub\": \"https://w3id.org/np/RAqmVeNbWgL7sNtsr9GqdX0ZTa6aQf3itQmort-JMy4tM\",\n",
      "    \"search_strategy_nanopub\": \" \",\n",
      "    \"search_execution_nanopub\": \" \"\n",
      "  },\n",
      "  \"studies\": [\n",
      "    {\n",
      "      \"uri\": \"https://doi.org/10.5281/zenodo.17538314\",\n",
      "      \"label\": \"Ethics of Environmental and Biodiversity Data. When Data Travel, Do the Benefits Return? Post\\u2013Living Data 2025 Report\",\n",
      "      \"metadata\": {\n",
      "        \"authors\": \"[\\\"Silva-Morales, Milena-Jael\\\", \\\"Navarrete, Yasm\\\\u00edn\\\"]\",\n",
      "        \"year\": 2025,\n",
      "        \"journal\": \"\",\n",
      "        \"doi\": \"10.5281/zenodo.17538314\",\n",
      "        \"abstract\": \"\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"uri\": \"https://doi.org/10.3390/rs13112221\",\n",
      "      \"label\": \"An Efficient Approach Based on Privacy-Preserving Deep Learning for Satellite Image Classification\",\n",
      "      \"metadata\": {\n",
      "        \"authors\": \"[\\\"Munirah Alkhelaiwi\\\", \\\"Wadii Boulila\\\", \\\"Jawad Ahmad\\\", \\\"Anis Koub\\\\u00e2a\\\", \\\"Maha Driss\\\"]\",\n",
      "        \"year\": 2021,\n",
      "        \"journal\": \"\",\n",
      "        \"doi\": \"10.3390/rs13112221\",\n",
      "        \"abstract\": \"\"\n",
      "      }\n",
      "    },\n",
      "    {\n",
      "      \"uri\": \"https://doi.org/10.5281/zenodo.17793473\",\n",
      "      \"label\": \"Ethics of Environmental and Biodiversity Data. When Data Travel, Do the Benefits Return? Post\\u2013Living Data 2025 Report\",\n",
      "      \"metadata\": {\n",
      "        \"authors\": \"[\\\"Silva-Morales, Milena-Jael\\\", \\\"Navarrete, Yasm\\\\u00edn\\\"]\",\n",
      "        \"year\": 2025,\n",
      "        \"journal\": \"\",\n",
      "        \"doi\": \"10.5281/zenodo.17793473\",\n",
      "        \"abstract\": \"\"\n",
      "      }\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "... and 4 more studies\n"
     ]
    }
   ],
   "source": [
    "# Show sample of the generated JSON\n",
    "print(\"Sample of study_inclusion.json:\\n\")\n",
    "preview = {\n",
    "    \"review_metadata\": study_inclusion_config[\"review_metadata\"],\n",
    "    \"provenance\": study_inclusion_config[\"provenance\"],\n",
    "    \"studies\": study_inclusion_config[\"studies\"][:3]  # First 3 studies\n",
    "}\n",
    "print(json.dumps(preview, indent=2, default=str))\n",
    "print(f\"\\n... and {len(studies) - 3} more studies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
